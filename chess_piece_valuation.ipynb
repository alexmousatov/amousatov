{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97ef0fa-00d2-4c9c-a0a6-6fd540664dff",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Chess Piece Evaluation and Result Prediction </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a82689-73cd-4b01-b1ea-e3a93f9f6bc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Import libraries and Load Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ae4c3-5f68-49f5-bb69-b4e6719616ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "\n",
    "# cleaning\n",
    "import re \n",
    "\n",
    "# modelling process\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# neural network models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# chess module\n",
    "import chess\n",
    "from chess import pgn\n",
    "from chess import Board\n",
    "\n",
    "# math \n",
    "import math\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bdc443-12f6-4eb8-9e19-9ac6f0ed446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "directory = os.getcwd()\n",
    "with open(directory + \"/raw_fics.txt\", 'r') as f:\n",
    "    raw_data_fics = f.read()\n",
    "with open(directory + \"/raw_pgnmentor.txt\", 'r', encoding = \"latin-1\") as f:\n",
    "    raw_data_pgnmentor = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be86dbc-0317-4904-8b29-87ee05ecb7f6",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Data Cleaning</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af73581-509a-4360-abae-53418ed58adc",
   "metadata": {},
   "source": [
    "I have dataframes containing chess games from two different sources. One is from 'pgnmentor.com' and carries data from official tournaments between chess players with Elo scores over 2000, considered 'experts.' The other is from the Free Internet Chess Server (FICS) and contains games from players with Elo scores from more inexperienced players; I will restrict to chess players with Elo scores between 1000 and 1600. \n",
    "\n",
    "The data I've collected from these two sources are in somewhat dirty text files, with lots of missing information and non-uniform formatting between games. I clean both in the hidden code blocks that follow, to the point that we can represent the data in dataframes instead of text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639cca2e-1c50-47ab-880b-85a159bf874d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### CLEANING THE RAW FICS DATA ### \n",
    "\n",
    "# Split the text file into individual games\n",
    "temp = raw_data_fics.split('[Event')[1:] \n",
    "\n",
    "# Remove all games where 1+ players are computers\n",
    "computer_indices = reversed([i for i in range(len(temp)) if \"Comp\" in temp[i]])\n",
    "for index in computer_indices:\n",
    "    temp.pop(index)\n",
    "    \n",
    "# Organize into dataframe\n",
    "temp = [x.replace('\\n', \" \").split(']') for x in temp] # Split the entries for each game\n",
    "temp = [[(x.split('\"')[1] if len(x.split('\"')) > 1 else x)  for x in game] for game in temp] # Extract data from between quotations\n",
    "columns = [\"GameType\", \"Site\", \"GameNo\", \"White\", \"Black\", \"WhiteElo\", \"BlackElo\", \"WhiteRD\", \"BlackRD\", \"TimeControl\", \"Date\", \n",
    "           \"Time\", \"WhiteClock\", \"BlackClock\", \"ECO\", \"PlyCount\", \"Result\", \"PGN\"]\n",
    "unfeatured_fics = pd.DataFrame(temp, columns = columns)\n",
    "\n",
    "# Drop miscellaneous columns we won't need \n",
    "columns_to_drop = [\"GameType\", \"Site\", \"GameNo\", \"White\", \"Black\", \"WhiteRD\", \"BlackRD\"]\n",
    "unfeatured_fics.drop(columns_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "# Remove games that were won or lost by internet disconnection\n",
    "unfeatured_fics = unfeatured_fics[unfeatured_fics[\"PGN\"].apply(lambda x: \"disconnection\" not in x)]\n",
    "\n",
    "# Remove information on how the game was won or lost (distinguising checkmate and resignation)\n",
    "unfeatured_fics[\"PGN\"] = unfeatured_fics[\"PGN\"].apply(lambda s: re.sub(\"\\{.*\\}\",\"\", s) )\n",
    "\n",
    "# Let the \"Result\" column contain only values 0 (white wins), 1 (black wins), or 2 (tie)\n",
    "unfeatured_fics[\"Result\"].replace({\"1-0\": 0, \"0-1\": 1, \"1/2-1/2\": 2}, inplace = True)\n",
    "\n",
    "# Convert these columns from object type to int type \n",
    "unfeatured_fics[\"WhiteElo\"], unfeatured_fics[\"BlackElo\"]  =  unfeatured_fics[\"WhiteElo\"].astype(int), unfeatured_fics[\"BlackElo\"].astype(int)\n",
    "\n",
    "# Select only the games where players have an Elo rating between 1000 and 1600\n",
    "unfeatured_fics = unfeatured_fics[(unfeatured_fics[\"WhiteElo\"] <= 1600) & (unfeatured_fics[\"WhiteElo\"] >= 1000)\\\n",
    "                                 & (unfeatured_fics[\"BlackElo\"] <= 1600) & (unfeatured_fics[\"BlackElo\"] >= 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7e563b-fcf3-42dc-a9dd-b6eb71482ea9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### CLEANING THE RAW PGNMENTOR DATA ### \n",
    "\n",
    "# Separate the text file into individual games \n",
    "temp = raw_data_pgnmentor.split('[Event ')[1:]\n",
    "\n",
    "# Extract features for each game \n",
    "temp = [game.replace('\\n', \" \").split(']') for game in temp] # For each game, split the different features\n",
    "temp = [[(x.split('\"')[1] if len(x.split('\"')) > 1 else x)  for x in game] for game in temp] # Extract information from inside quotations\n",
    "\n",
    "# Most games have exactly 11 features, but a small number (about 400, or 1/1000th of all games) have a different format. Remove them.\n",
    "remove_indices = reversed([i for i in range(len(temp)) if len(temp[i]) != 11])\n",
    "for index in remove_indices:\n",
    "    temp.pop(index)\n",
    "\n",
    "# Create dataframe from data\n",
    "columns = [\"Event\", \"Site\", \"Date\", \"Round\", \"White\", \"Black\", \"Result\", \"WhiteElo\", \"BlackElo\", \"ECO\", \"PGN\"]\n",
    "unfeatured_pgnmentor = pd.DataFrame(temp, columns = columns)\n",
    "\n",
    "# Remove duplicate games. \n",
    "# The games were originally recorded by player, so that almost all games are recorded twice - from the perspective of white and of black. \n",
    "# This can be fixed by requiring White player's name < Black player's name\n",
    "unfeatured_pgnmentor = unfeatured_pgnmentor[unfeatured_pgnmentor[\"White\"] < unfeatured_pgnmentor[\"Black\"]]\n",
    "\n",
    "# In the column \"Result\", record the result of each game as 0 for white wins, 1 for black wins, 2 for tie\n",
    "unfeatured_pgnmentor[\"Result\"].replace({\"1-0\": 0, \"0-1\": 1, \"1/2-1/2\" : 2}, inplace = True) \n",
    "\n",
    "# Remove the two entries with a missing value (written as '*') as the Result \n",
    "unfeatured_pgnmentor.drop(unfeatured_pgnmentor[unfeatured_pgnmentor[\"Result\"] == \"*\"].index, inplace = True)\n",
    "\n",
    "# Replace empty strings with np.nan\n",
    "unfeatured_pgnmentor.replace({\"\": np.nan}, inplace = True)\n",
    "\n",
    "# Fix dtypes\n",
    "unfeatured_pgnmentor[\"Result\"] = unfeatured_pgnmentor[\"Result\"].astype(int)\n",
    "unfeatured_pgnmentor[\"WhiteElo\"] = unfeatured_pgnmentor[\"WhiteElo\"].astype(float) \n",
    "unfeatured_pgnmentor[\"BlackElo\"] = unfeatured_pgnmentor[\"BlackElo\"].astype(float) \n",
    "\n",
    "# Remove leading and trailing whitespace for PGN feature\n",
    "unfeatured_pgnmentor[\"PGN\"] = unfeatured_pgnmentor[\"PGN\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f419e-a038-4bfb-85f8-d8ec13b73ec6",
   "metadata": {},
   "source": [
    "See below for what our dataframes look like now. Some of the key columns here are:\n",
    "* WhiteElo: Elo score of White\n",
    "* BlackElo: Elo score of Black\n",
    "* ECO: Classification for chess openings\n",
    "* Result: 0 if White Wins, 1 if Black Wins, 2 if Tie \n",
    "* PGN: PGN stands for Portable Game Notation. It is a compact way to store all information about every move the players made throughout the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca389de8-0a63-45fc-b2fb-bfe87d2aa5f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>TimeControl</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>WhiteClock</th>\n",
       "      <th>BlackClock</th>\n",
       "      <th>ECO</th>\n",
       "      <th>PlyCount</th>\n",
       "      <th>Result</th>\n",
       "      <th>PGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1356</td>\n",
       "      <td>1296</td>\n",
       "      <td>1200+10</td>\n",
       "      <td>2021.12.28</td>\n",
       "      <td>11:58:00</td>\n",
       "      <td>0:20:00.000</td>\n",
       "      <td>0:20:00.000</td>\n",
       "      <td>B07</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>1. e4 d6 2. d4 Nf6 3. Nc3 Ng4 4. Qe2 h5 5. h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396</td>\n",
       "      <td>1389</td>\n",
       "      <td>900+1</td>\n",
       "      <td>2021.12.27</td>\n",
       "      <td>11:18:00</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>C25</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1. e4 e5 2. Nc3 Bb4 3. Bc4 Bxc3 4. bxc3 Nf6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>1800+30</td>\n",
       "      <td>2021.12.27</td>\n",
       "      <td>08:14:00</td>\n",
       "      <td>0:30:00.000</td>\n",
       "      <td>0:30:00.000</td>\n",
       "      <td>D00</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1. d4 d5 2. Bf4 e6 3. Nf3 Bd6 4. Bg5 Nf6 5. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1388</td>\n",
       "      <td>1388</td>\n",
       "      <td>900+0</td>\n",
       "      <td>2021.12.26</td>\n",
       "      <td>20:55:00</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>C62</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. Bxc6+ bxc6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1396</td>\n",
       "      <td>1380</td>\n",
       "      <td>900+0</td>\n",
       "      <td>2021.12.26</td>\n",
       "      <td>20:28:00</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>0:15:00.000</td>\n",
       "      <td>D02</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1. d4 d5 2. Nf3 Nc6 3. e3 a6 4. a4 Bg4 5. Be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WhiteElo  BlackElo TimeControl        Date      Time   WhiteClock  \\\n",
       "2      1356      1296     1200+10  2021.12.28  11:58:00  0:20:00.000   \n",
       "3      1396      1389       900+1  2021.12.27  11:18:00  0:15:00.000   \n",
       "4      1289      1306     1800+30  2021.12.27  08:14:00  0:30:00.000   \n",
       "5      1388      1388       900+0  2021.12.26  20:55:00  0:15:00.000   \n",
       "6      1396      1380       900+0  2021.12.26  20:28:00  0:15:00.000   \n",
       "\n",
       "    BlackClock  ECO PlyCount  Result  \\\n",
       "2  0:20:00.000  B07      163       2   \n",
       "3  0:15:00.000  C25       59       0   \n",
       "4  0:30:00.000  D00       56       1   \n",
       "5  0:15:00.000  C62       89       0   \n",
       "6  0:15:00.000  D02       68       1   \n",
       "\n",
       "                                                 PGN  \n",
       "2    1. e4 d6 2. d4 Nf6 3. Nc3 Ng4 4. Qe2 h5 5. h...  \n",
       "3    1. e4 e5 2. Nc3 Bb4 3. Bc4 Bxc3 4. bxc3 Nf6 ...  \n",
       "4    1. d4 d5 2. Bf4 e6 3. Nf3 Bd6 4. Bg5 Nf6 5. ...  \n",
       "5    1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. Bxc6+ bxc6 ...  \n",
       "6    1. d4 d5 2. Nf3 Nc6 3. e3 a6 4. a4 Bg4 5. Be...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfeatured_fics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46142dd0-949f-40e6-82d0-38d63472183f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Site</th>\n",
       "      <th>Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Result</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>ECO</th>\n",
       "      <th>PGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lloyds Bank op</td>\n",
       "      <td>London</td>\n",
       "      <td>1984.??.??</td>\n",
       "      <td>1</td>\n",
       "      <td>Adams, Michael</td>\n",
       "      <td>Sedgwick, David</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C05</td>\n",
       "      <td>1.e4 e6 2.d4 d5 3.Nd2 Nf6 4.e5 Nfd7 5.f4 c5 6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lloyds Bank op</td>\n",
       "      <td>London</td>\n",
       "      <td>1984.??.??</td>\n",
       "      <td>3</td>\n",
       "      <td>Adams, Michael</td>\n",
       "      <td>Dickenson, Neil F</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>C07</td>\n",
       "      <td>1.e4 e6 2.d4 d5 3.Nd2 c5 4.exd5 Qxd5 5.Ngf3 cx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lloyds Bank op</td>\n",
       "      <td>London</td>\n",
       "      <td>1984.??.??</td>\n",
       "      <td>6</td>\n",
       "      <td>Adams, Michael</td>\n",
       "      <td>Levitt, Jonathan</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>B99</td>\n",
       "      <td>1.e4 c5 2.Nf3 d6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 a6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lloyds Bank op</td>\n",
       "      <td>London</td>\n",
       "      <td>1984.??.??</td>\n",
       "      <td>9</td>\n",
       "      <td>Adams, Michael</td>\n",
       "      <td>Saeed, Saeed Ahmed</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>B56</td>\n",
       "      <td>1.e4 c5 2.Nf3 Nc6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BCF-ch</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>1985.??.??</td>\n",
       "      <td>1</td>\n",
       "      <td>Adams, Michael</td>\n",
       "      <td>Singh, Sukh Dave</td>\n",
       "      <td>2</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>B70</td>\n",
       "      <td>1.e4 c5 2.Nf3 d6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 g6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Event       Site        Date Round           White  \\\n",
       "0  Lloyds Bank op     London  1984.??.??     1  Adams, Michael   \n",
       "1  Lloyds Bank op     London  1984.??.??     3  Adams, Michael   \n",
       "4  Lloyds Bank op     London  1984.??.??     6  Adams, Michael   \n",
       "5  Lloyds Bank op     London  1984.??.??     9  Adams, Michael   \n",
       "6          BCF-ch  Edinburgh  1985.??.??     1  Adams, Michael   \n",
       "\n",
       "                Black  Result  WhiteElo  BlackElo  ECO  \\\n",
       "0     Sedgwick, David       0       NaN       NaN  C05   \n",
       "1   Dickenson, Neil F       0       NaN    2230.0  C07   \n",
       "4    Levitt, Jonathan       2       NaN    2370.0  B99   \n",
       "5  Saeed, Saeed Ahmed       0       NaN    2430.0  B56   \n",
       "6    Singh, Sukh Dave       2    2360.0    2080.0  B70   \n",
       "\n",
       "                                                 PGN  \n",
       "0  1.e4 e6 2.d4 d5 3.Nd2 Nf6 4.e5 Nfd7 5.f4 c5 6....  \n",
       "1  1.e4 e6 2.d4 d5 3.Nd2 c5 4.exd5 Qxd5 5.Ngf3 cx...  \n",
       "4  1.e4 c5 2.Nf3 d6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 a6...  \n",
       "5  1.e4 c5 2.Nf3 Nc6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 d...  \n",
       "6  1.e4 c5 2.Nf3 d6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 g6...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfeatured_pgnmentor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac5c548-6c32-4670-b4a3-004fc3467656",
   "metadata": {},
   "source": [
    "We are not interested in training our classification model to predict a 'Tie' result, as opposed to White or Black winning. Ties will only make our model harder to train, without teaching us about which player has an advantage at any point in the game. I drop all rows that have ties in the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aeb8264-9fdb-4d07-8efd-7d48b1b750d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping ties. \n",
    "unfeatured_pgnmentor = unfeatured_pgnmentor[unfeatured_pgnmentor[\"Result\"] != 2]\n",
    "unfeatured_fics = unfeatured_fics[unfeatured_fics[\"Result\"] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e64c2de4-8708-4aad-943f-826f10bd2692",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 119218 expert games and 17292 amateur games in our remaining data after cleaning.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} expert games and {} amateur games in our remaining data after cleaning.'.format(unfeatured_pgnmentor.shape[0], unfeatured_fics.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2979930-4b99-43be-9f77-9cbb9d286a9c",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Feature Engineering (Part 1)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ea9f9-8b08-43d8-9da2-e99949d08eeb",
   "metadata": {},
   "source": [
    "In our current dataframes, all the information we have about the chess games lies in the 'PGN' column. The PGN feature contains long strings giving each move by White and Black, in order. \n",
    "\n",
    "See the example below. Every pair of moves from white and black is numbered, '1.', '2.', and so on. Each move is contains a few parts:\n",
    "* The piece: The pieces are represented as K (king), Q (queen), R (rook), B (bishop), N (knight). White's pieces are capital letters, and Black's pieces are lower-case letters. If no piece is specified, a pawn is moving. \n",
    "* The position a piece moves to: These positions contain a letter and number, like 'e4'. The letter refers to the column or 'file' in the chess board, and the number refers to the row or 'rank'. See the chess board below to see how each letter and number combination maps to a position on the board. \n",
    "* The letter 'x': if 'x' is present in the move, that means some piece on the opposing side was captured. \n",
    "* Castling: Castling is written as 'O-O' (King's Castle) or 'O-O-O' (Queen's Castle). \n",
    "* Check and Checkmate: If a player checks another player, a '+' is appended to the end of the move. If a checkmate occurs, a '#' is appended to the end of the move. \n",
    "\n",
    "At the end of the string, the result of the game is written as 1-0 (White wins) or 0-1 (Black wins). Note that ties have been removed from our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c672576-60a2-4cf2-8f14-0565ec9f4884",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a game in PGN format is as follows\n",
      "  1. e4 e5 2. Nc3 Bb4 3. Bc4 Bxc3 4. bxc3 Nf6 5. d3 a6 6. f4 exf4 7. a3 O-O 8. Nf3 d5 9. exd5 Nxd5 10. O-O Ne3 11. Bxe3 fxe3 12. Ne5 Nc6 13. Nxf7 Qd7 14. Ne5+ Kh8 15. Nxd7 Rxf1+ 16. Qxf1 Bxd7 17. Re1 Ne5 18. Bb3 Ng4 19. g3 a5 20. a4 Re8 21. Bf7 Rf8 22. c4 Be6 23. Qe2 Rxf7 24. d4 Nf6 25. Qxe3 Bd7 26. d5 Bxa4 27. Rf1 Bxc2 28. Rxf6 Kg8 29. Qe8+ Rf8 30. Qxf8#  1-0   \n"
     ]
    }
   ],
   "source": [
    "print('An example of a game in PGN format is as follows')\n",
    "print(unfeatured_fics.iloc[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c247d2-ae63-4f61-851d-dc7242c8c72f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess.Board()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf022b8-acc4-4076-b338-72532d0471ee",
   "metadata": {},
   "source": [
    "It is clear that we will not be able to predict who wins a game using only PGN format as a feature. The format is simply too esoteric; when one player captures another player's piece, we don't even know what piece was captured unless we try to trace back who was last in that position! We have to help out our forecasting model, by extracting key features from the game and providing those as features. \n",
    "\n",
    "Towards that end, I engineer a number of features that will be valuable to identifying which side has a winning advantage. For a single, pre-determined time in the game, I will make these features:\n",
    "* *How many of each piece* does each player have\n",
    "* How much *mobility* does each player have, where mobility is defined as the total number of legal moves a player can make \n",
    "* Number of *blocked pawns*: pawns that cannot move forward because an enemy piece is directly in front of it. \n",
    "* Number of *isolated pawns*: pawns that have no friendly pawns in neighboring files. \n",
    "* Number of *doubled pawns*: pawns that have at least one other friendly pawn in the same rank. \n",
    "\n",
    "Having more pieces and higher mobility are both positives that will improve a player's chance of winning. Having blocked, isolated, or doubled pawns is considered a weakness that harms a player's chance of winning. At least some of these features should help us predict who will win the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89487dd9-ed36-4f36-8ed8-f531d2b43b49",
   "metadata": {},
   "source": [
    "To engineer all these features, I need to define a number of functions, all in the hidden code blocks below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "53b9e3f1-c976-42ad-9158-1b86e2952a4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of chess pieces and corresponding shortenings ('r' for black rook, 'R' for white rook, etc.)\n",
    "pieces = [\"Rook\", \"Knight\", \"Bishop\", \"Pawn\", \"Queen\", \"King\"]\n",
    "black = {\"Rook\": \"r\", \"Knight\": \"n\", \"Bishop\": \"b\", \"Pawn\": \"p\", \"Queen\": \"q\", \"King\": \"k\"}\n",
    "white = {\"Rook\": \"R\", \"Knight\": \"N\", \"Bishop\": \"B\", \"Pawn\": \"P\", \"Queen\": \"Q\", \"King\": \"K\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3d49741a-b420-4d11-878d-62c6abd29f8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR REFORMATTING CHESS GAME NOTATION \n",
    "\n",
    "# Convert PGN format to FEN format, where the FEN notation records the position at a specific point in the game\n",
    "def convert_PGN_to_FEN(pgn: str, nMoves: int) -> str:\n",
    "    moves = [(x[1] if len(x) == 2 else x[0]) for x in [x.split('.') for x in pgn.split()]]\n",
    "    # If not enough moves in the game\n",
    "    if len(moves) - 1 < num_moves: # -1 removes game result (1-0 or equivalent)\n",
    "        return np.nan\n",
    "    # Make all moves, return final board position \n",
    "    board = chess.Board()\n",
    "    for i in range(nMoves):\n",
    "        board.push_san(moves[i])\n",
    "    return board.fen()\n",
    "\n",
    "# Formatting: return simplified FEN that contains only positional information\n",
    "def simplify_FEN(FEN: str) -> str:\n",
    "    return FEN.split(' ')[0] \n",
    "\n",
    "# Formatting: converting FEN to a matrix (list of lists) with shape 8 by 8\n",
    "def convert_FEN_to_Matrix(FEN: str) -> list: \n",
    "    FEN = simplify_FEN(FEN)\n",
    "    FEN = [line for line in FEN.split('/')]\n",
    "    board = []\n",
    "    for line in FEN:\n",
    "        t = [list(char.replace(char, \"0\" * int(char)) if char.isdigit() else char) for char in line]\n",
    "        board.append([item for sublist in t for item in sublist])\n",
    "    return board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72eee96-6088-4849-bd24-cdd3d0e62bda",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs score of a player, using 95331\n",
    "def get_traditional_score(simple_FEN: str, player: str) -> int:\n",
    "    scoring = [5,3,3,1,9] # rook, knight, bishop, pawn, queen\n",
    "    piecesCount = count_pieces(simple_FEN, player)\n",
    "    return sum([count * score for count, score in zip(piecesCount, scoring)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "505838f2-fc8f-4b9f-a803-d175a92be9bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR FEATURE ENGINEERING:\n",
    "#    Count of each piece\n",
    "#    Traditional score of each side (based on 95331 heuristic) \n",
    "#    Difference in mobilities of players, where mobility is defined as the total number of legal moves\n",
    "#    Number of 'bad' pawns\n",
    "\n",
    "# Outputs counts of each piece in [\"Rook\", \"Knight\", \"Bishop\", \"Pawn\", \"Queen\"], for a specific player \n",
    "def count_pieces(simple_FEN: str, player: str) -> list:\n",
    "    lst = []\n",
    "    if player == \"white\": \n",
    "        for piece in white:\n",
    "            if piece == \"King\": continue\n",
    "            lst.append(simple_FEN.count(white[piece]))\n",
    "    else:\n",
    "        for piece in black:\n",
    "            if piece == \"King\": continue\n",
    "            lst.append(simple_FEN.count(black[piece]))\n",
    "    return lst\n",
    "\n",
    "# Outputs differences (white - black) in counts of each piece, in order [\"Rook\", \"Knight\", \"Bishop\", \"Pawn\", \"Queen\"]\n",
    "def get_pieces_diff(simple_FEN: str) -> list:\n",
    "    return [x - y for x,y in zip(count_pieces(simple_FEN, \"white\"), count_pieces(simple_FEN, \"black\"))]\n",
    "\n",
    "# Outputs difference (white - black) in mobility between players.\n",
    "def get_mobility_diff(PGN: str, nMoves: int, FEN: str) -> int:\n",
    "    \n",
    "    board = chess.Board(FEN)\n",
    "    moves = list(filter(None, [(x.split('.')[1] if ('.' in x) else x.split('.')[0]) for x in PGN.split()]))\n",
    "    \n",
    "    # Mobility after nMoves\n",
    "    if nMoves % 2 == 0:\n",
    "        white_mobility = len(list(board.legal_moves))\n",
    "    else:    \n",
    "        black_mobility = len(list(board.legal_moves))\n",
    "    \n",
    "    # Mobility after nMoves + 1\n",
    "    board.push_san(moves[nMoves])\n",
    "    if nMoves % 2 == 0: \n",
    "        black_mobility = len(list(board.legal_moves))\n",
    "    else: \n",
    "        white_mobility = len(list(board.legal_moves))\n",
    "    return (white_mobility - black_mobility)\n",
    "\n",
    "# Count bad pawns for a given player. Output is a list of the counts, in the order Blocked, Isolated, Doubled\n",
    "def count_bad_pawns(matrix: list, player: str) -> list:\n",
    "    pawn = {\"white\": \"P\", \"black\": \"p\"}\n",
    "    blocked = isolated = doubled = 0\n",
    "    # Look at each square of the board\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            # Check for pawn at the square row, col\n",
    "            if matrix[row][col] == pawn[player]:\n",
    "                # Is blocked? \n",
    "                if player == \"black\" and matrix[row + 1][col].isupper():\n",
    "                    blocked += 1\n",
    "                elif player == \"white\" and matrix[row - 1][col].islower():\n",
    "                    blocked += 1\n",
    "                # Is isolated?\n",
    "                if ((col - 1 < 0) or (pawn[player] not in [matrix[row][col - 1] for row in range(8)])) \\\n",
    "                and ((col + 1 > 7) or (pawn[player] not in [matrix[row][col + 1] for row in range(8)])):\n",
    "                    isolated += 1\n",
    "                # Is doubled?\n",
    "                for rowp in range(8):\n",
    "                    if rowp == row: continue\n",
    "                    if pawn[player] in matrix[rowp][col]: \n",
    "                        doubled += 1\n",
    "                        break\n",
    "    return [blocked, isolated, doubled]\n",
    "\n",
    "def get_bad_pawns_diff(matrix: list) -> list:\n",
    "    return [x - y for x, y in zip(count_bad_pawns(matrix, \"white\"), count_bad_pawns(matrix, \"black\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732ee4f-54e8-4f24-b470-1d8df682f763",
   "metadata": {},
   "source": [
    "I also need to decide at what point in each game I want to make a prediction on who will win. Naively, I could choose to make my prediction after a certain, fixed number of turns for each game. However, this does not actually make sense in practice, because the pace of chess games can vary dramatically, so that after the same number of total moves, one game could still be in early midgame while another is already in endgame. I don't want to ask too much of my classification model, because doing so will reduce its performance, and that includes not asking it to try to distinguish different stages and distinguish different predictive properties of different stages. \n",
    "\n",
    "I define two points in a chess game at which I want to make predictions. I use the traditional scoring system for pieces in chess, 9 points for queens, 5 points for rooks, 3 points for bishops and knights, and 1 point for pawns. I then define these two times in 'midgame' and 'endgame' as follows:\n",
    "* Midgame: The moment at which both White and Black have total scores that drop to or below 25. \n",
    "* Endgame: The moment at which both White and Black have total scores that drop to or below 13. \n",
    "\n",
    "The threshold of 13 to define the beginning of endgame agrees reasonably well with most definitions of endgame; for example, 13 was chosen as the threshold by Speelman in his Endgame Preparation book in 1981. The threshold of 25 is fairly arbitrary, but certainly defines a point where enough pieces have been captured to escape the 'opening' stage. \n",
    "\n",
    "The function defined below outputs the board (in 'FEN' format) at the chosen game stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1a45cbbc-7401-4798-9fd3-ca9ef3046e1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the FEN of the board when both players' 95331 scores first fall below a certain threshold value. \n",
    "#     Output in the form: half-move-value at which threshold is crossed, FEN at that half-move\n",
    "#     ex. threshold = 13 for beginning of endgame (Speelman)\n",
    "def get_stage_FEN(PGN: str, threshold: int) -> tuple:\n",
    "    \n",
    "    # From pgn, get a list of all moves \n",
    "    moves = list(filter(None, [(x.split('.')[1] if ('.' in x) else x.split('.')[0]) for x in PGN.split()])) # removes emptry strings\n",
    "    nHalfMoves = len(moves) - 1\n",
    "    \n",
    "    # Get scores at end of game \n",
    "    board = chess.Board()\n",
    "    for i in range(nHalfMoves): board.push_san(moves[i])\n",
    "    fen = board.fen()\n",
    "    whiteScore, blackScore = get_traditional_score(fen, 1), get_traditional_score(fen, 2)\n",
    "\n",
    "    # Return null\n",
    "    if whiteScore > threshold or blackScore > threshold: return np.nan, np.nan\n",
    "\n",
    "    # Binary search: Pop moves to go to an earlier stage of the game. Push moves to go to a later stage of the game.\n",
    "    left = 0\n",
    "    right = currMove = nHalfMoves \n",
    "    while left < right:\n",
    "        # Update board\n",
    "        steps = math.ceil((right - left) / 2)\n",
    "        # Push moves to decrease scores to threshold \n",
    "        if whiteScore > threshold or blackScore > threshold: \n",
    "            for _ in range(steps):\n",
    "                board.push_san(moves[currMove])\n",
    "                currMove += 1\n",
    "        # Pop moves to increase scores to threshold\n",
    "        else: \n",
    "            for _ in range(steps):\n",
    "                board.pop()\n",
    "                currMove -= 1\n",
    "\n",
    "        # Update scores \n",
    "        fen = board.fen()\n",
    "        whiteScore, blackScore = get_traditional_score(fen, 1), get_traditional_score(fen, 2)\n",
    "\n",
    "        # Update \"left\" and \"right\" \n",
    "        if whiteScore <= threshold and blackScore <= threshold:\n",
    "            if right == currMove:\n",
    "                break\n",
    "            right = currMove\n",
    "        else:\n",
    "            left = (currMove if currMove != left else currMove + 1)\n",
    "    \n",
    "    # It is not always sensible to try to predict the game result if we're already at the end of the game. Return null.\n",
    "    if currMove == nHalfMoves:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    return currMove, board.fen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c296163-237b-4f2b-af6a-74288854573e",
   "metadata": {},
   "source": [
    "Using my functions above, I now engineer all the features I'll need for my two chosen points in each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "20930dc5-f2a3-44b8-9e9b-319b92ec533c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dfs stores the 4 dataframes in the order: amateur midgame, amateur endgame, expert midgame, expert endgame \n",
    "dfs = []\n",
    "for data in [unfeatured_fics, unfeatured_pgnmentor]:\n",
    "    for threshold in [25,13]:\n",
    "        df = pd.DataFrame(index = data.index, columns = [\"Turn\", \"FEN\", \"PGN\", \"Result\"])\n",
    "        df[\"PGN\"], df[\"Result\"] = data[\"PGN\"], data[\"Result\"]\n",
    "        for index in data.index:\n",
    "            df.loc[index, [\"Turn\", \"FEN\"]] = get_stage_FEN(data.loc[index, \"PGN\"], threshold)\n",
    "        df.dropna(inplace = True)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "407e40f5-9748-4980-8739-d3f30e96b7de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featured_dfs = []\n",
    "for data in dfs:\n",
    "    # Initialize dataframe to carry new features\n",
    "    index = data.index\n",
    "    pieces_columns, bad_pawns_columns = [piece + \"Diff\" for piece in pieces[:5]], [\"BlockedPawnDiff\", \"IsolatedPawnDiff\", \"DoublePawnDiff\"]\n",
    "    features_data = pd.DataFrame(index = index, columns = pieces_columns + bad_pawns_columns + [\"MobilityDiff\"])\n",
    "    \n",
    "    for index in data.index:\n",
    "        # Some preprocessing of data in one row\n",
    "        nMoves, FEN, PGN = data.loc[index, \"Turn\"], data.loc[index, \"FEN\"], data.loc[index, \"PGN\"]\n",
    "        simple_FEN = simplify_FEN(FEN)\n",
    "        matrix = convert_FEN_to_Matrix(FEN)\n",
    "        \n",
    "        # Feature engineering for differences in pieces \n",
    "        diffs = get_pieces_diff(simple_FEN)\n",
    "        for i, piece in enumerate(pieces[:5]):\n",
    "            features_data[piece + \"Diff\"][index] = diffs[i]       \n",
    "            \n",
    "        # Feature engineering for bad pawns\n",
    "        features_data.loc[index, bad_pawns_columns] = get_bad_pawns_diff(matrix)\n",
    "        \n",
    "        # Feature engineering for mobility\n",
    "        features_data.loc[index, \"MobilityDiff\"] = get_mobility_diff(PGN, nMoves, FEN)\n",
    "        \n",
    "    featured_dfs.append(pd.concat([data, features_data], axis = 1))\n",
    "AmateurMidData, AmateurEndData, ExpertMidData, ExpertEndData = featured_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abc00d-4bb2-4744-9d02-74e568e9b420",
   "metadata": {},
   "source": [
    "I save my data with all added features, for easy re-loading. An example of what the dataframes now look like is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "48987f25-375c-4485-ab31-3ab8eb8cbfa2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save results to file \n",
    "# AmateurMidData.to_csv(\"AmateurMid.csv\")\n",
    "# AmateurEndData.to_csv(\"AmateurEnd.csv\")\n",
    "# ExpertMidData.to_csv(\"ExpertMid.csv\")\n",
    "# ExpertEndData.to_csv(\"ExpertEnd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aeb6a72-4f1f-45f5-8cb0-a99257282c4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AmateurMidgameData = pd.read_csv(\"AmateurMid.csv\", index_col = 0)\n",
    "AmateurEndgameData = pd.read_csv(\"AmateurEnd.csv\", index_col = 0)\n",
    "ExpertMidgameData = pd.read_csv(\"ExpertMid.csv\", index_col = 0)\n",
    "ExpertEndgameData = pd.read_csv(\"ExpertEnd.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efdea894-0082-462d-a88b-03449cc74c92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turn</th>\n",
       "      <th>FEN</th>\n",
       "      <th>PGN</th>\n",
       "      <th>Result</th>\n",
       "      <th>RookDiff</th>\n",
       "      <th>KnightDiff</th>\n",
       "      <th>BishopDiff</th>\n",
       "      <th>PawnDiff</th>\n",
       "      <th>QueenDiff</th>\n",
       "      <th>BlockedPawnDiff</th>\n",
       "      <th>IsolatedPawnDiff</th>\n",
       "      <th>DoublePawnDiff</th>\n",
       "      <th>MobilityDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>r1b2r1k/1ppN2pp/p1n5/8/2B5/P1PPp3/2P3PP/R2Q1RK...</td>\n",
       "      <td>1. e4 e5 2. Nc3 Bb4 3. Bc4 Bxc3 4. bxc3 Nf6 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>r3r1k1/ppp2ppp/8/4bb2/4n3/2P1B3/PP3PPP/RN1R2K1...</td>\n",
       "      <td>1. d4 d5 2. Bf4 e6 3. Nf3 Bd6 4. Bg5 Nf6 5. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>6k1/2p4p/2p1r1p1/p2p1N1P/bq6/6Q1/5PP1/5RK1 w -...</td>\n",
       "      <td>1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. Bxc6+ bxc6 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57</td>\n",
       "      <td>r4rk1/p6p/1p3bp1/8/4b1P1/P1PQp3/1PK2P2/1RB3n1 ...</td>\n",
       "      <td>1. d4 e6 2. Nf3 Nf6 3. c3 d5 4. e3 b6 5. Qc2...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44</td>\n",
       "      <td>r5r1/3k1pb1/b2ppnpp/p7/4P3/1P2NN2/PB1P1PPP/R1R...</td>\n",
       "      <td>1. e4 e6 2. Nc3 c6 3. Nf3 h6 4. Be2 Qc7 5. O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Turn                                                FEN  \\\n",
       "3     29  r1b2r1k/1ppN2pp/p1n5/8/2B5/P1PPp3/2P3PP/R2Q1RK...   \n",
       "4     28  r3r1k1/ppp2ppp/8/4bb2/4n3/2P1B3/PP3PPP/RN1R2K1...   \n",
       "5     72  6k1/2p4p/2p1r1p1/p2p1N1P/bq6/6Q1/5PP1/5RK1 w -...   \n",
       "8     57  r4rk1/p6p/1p3bp1/8/4b1P1/P1PQp3/1PK2P2/1RB3n1 ...   \n",
       "10    44  r5r1/3k1pb1/b2ppnpp/p7/4P3/1P2NN2/PB1P1PPP/R1R...   \n",
       "\n",
       "                                                  PGN  Result  RookDiff  \\\n",
       "3     1. e4 e5 2. Nc3 Bb4 3. Bc4 Bxc3 4. bxc3 Nf6 ...       0         0   \n",
       "4     1. d4 d5 2. Bf4 e6 3. Nf3 Bd6 4. Bg5 Nf6 5. ...       1         0   \n",
       "5     1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. Bxc6+ bxc6 ...       0         0   \n",
       "8     1. d4 e6 2. Nf3 Nf6 3. c3 d5 4. e3 b6 5. Qc2...       1        -1   \n",
       "10    1. e4 e6 2. Nc3 c6 3. Nf3 h6 4. Be2 Qc7 5. O...       0         0   \n",
       "\n",
       "    KnightDiff  BishopDiff  PawnDiff  QueenDiff  BlockedPawnDiff  \\\n",
       "3            0           0         0          1                0   \n",
       "4            0          -1         0          0                0   \n",
       "5            1          -1        -3          0                0   \n",
       "8           -1          -1         0          1                0   \n",
       "10           1          -1         1          0                0   \n",
       "\n",
       "    IsolatedPawnDiff  DoublePawnDiff  MobilityDiff  \n",
       "3                  0               2           -27  \n",
       "4                  0               0            -9  \n",
       "5                 -1              -2            -8  \n",
       "8                 -1               0           -37  \n",
       "10                -1               0            12  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AmateurMidgameData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638478d-ad78-442f-81f0-fbca0d72d8bc",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Chess Piece Valuation and Game Result Prediction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b1506-e6af-413f-8969-a774880d5a06",
   "metadata": {},
   "source": [
    "There are two main goals of this section. One is to use a simple, *linear*, classification model like Logistic Regression or Support Vector Classifier to predict who will win the chess game. \n",
    "\n",
    "The second is to, from the fitted classification model, extract the coefficients that multiply each feature and are used to make the predictions. These coefficients, well-defined only in linear models, tell us the predictive value of each feature. For example, we'll get a number telling us how valuable White having an extra rook is towards White winning, versus any other piece. We can then compare the numbers, essentially chess piece values, with the more traditional scoring of 9, 5, 3, 3, 1 for queens, rooks, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0be0a0-e86c-4c58-8612-730eba814593",
   "metadata": {},
   "source": [
    "In the code block below, I train my classification model and make my predictions. I use each data set we have, for Amateur Midgame, Amateur Endgame, Expert Midgame, and Expert Endgame. I also train on two different sets of features: one includes *only* the differences in the number of pieces each player has, and the other also contains the bad-pawn (blocked, isolated, doubled pawns) and mobility features. \n",
    "\n",
    "I use Cohen's kappa score as an evaluation metric for my predictions. Cohen's kappa is a nice evaluation metric in our situation for a number of reasons. It is defined so that it describes the fraction of results predicted correctly, *excluding* those that were just predicted correctly by chance (i.e. a lucky guess). Cohen's kappa therefore avoid the biggest problem with 'accuracy', which is overinflated in an imbalanced classification problem by repeatedly guessing the more common class. Cohen's kappa is also more intuitive than an AUC-ROC score. \n",
    "\n",
    "I redo training and predictions multiple times to get 95% confidence intervals for my evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee9e3779-bbd4-4f0b-8101-cd4b472f57e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning run 1 of 8\n",
      "Beginning run 2 of 8\n",
      "Beginning run 3 of 8\n",
      "Beginning run 4 of 8\n",
      "Beginning run 5 of 8\n",
      "Beginning run 6 of 8\n",
      "Beginning run 7 of 8\n",
      "Beginning run 8 of 8\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "\n",
    "# Storage for logistic regression fitting parameters, and for evaluation metrics\n",
    "coefficients = [[] for _ in range(8)]\n",
    "kappas = [[] for _ in range(8)]\n",
    "baseline_kappas = [[] for _ in range(8)]\n",
    "\n",
    "\n",
    "# Feature groupings\n",
    "pieces = [\"Rook\", \"Knight\", \"Bishop\", \"Pawn\", \"Queen\", \"King\"]\n",
    "pieces_cols = [piece + \"Diff\" for piece in pieces[:5]]\n",
    "bad_pawns_cols = [\"BlockedPawnDiff\", \"IsolatedPawnDiff\", \"DoublePawnDiff\"]\n",
    "mobility_cols = [\"MobilityDiff\"]\n",
    "\n",
    "ctr = 0\n",
    "\n",
    "# Fit 4 sets of data, with 2 different feature spaces each\n",
    "for feature_space in [pieces_cols, pieces_cols + bad_pawns_cols + mobility_cols]:\n",
    "    for data in [AmateurMidgameData, AmateurEndgameData, ExpertMidgameData, ExpertEndgameData]:\n",
    "        print('Beginning run {} of 8'.format(ctr + 1))\n",
    "\n",
    "        # Get X and y, training and test\n",
    "        X = data[feature_space]\n",
    "        y = data[\"Result\"]\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify = y)\n",
    "\n",
    "            # Fit model and Make predictions \n",
    "            model = LogisticRegression(fit_intercept = False, class_weight = \"balanced\")\n",
    "                # tried liblinear, newton-cg, lbfgs  -  no difference\n",
    "                # tried adjusting C - no improvement \n",
    "                # fit_intercept = False - improves results \n",
    "                # class_weight = \"balanced\" - improves results \n",
    "            # model = SVC(kernel = \"linear\")\n",
    "                # SVC - no improvement over logistic regression\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Save fitting parameters and evaluation metrics \n",
    "            coefficients[ctr].append(model.coef_[0])\n",
    "            kappas[ctr].append(cohen_kappa_score(y_pred, y_test))\n",
    "            \n",
    "            # Make a new logistic model using standardized scores, and evaluate results \n",
    "            model = LogisticRegression()\n",
    "            model.coef_ = (- np.array([[5, 3, 3, 1, 9]]) if ctr < 4 else - np.array([[5,3,3,1,9,-0.5,-0.5,-0.5,0.1]]))\n",
    "            model.intercept_ = 0.\n",
    "            model.classes_= np.array([0, 1])\n",
    "            y_pred = model.predict(X_test.values)\n",
    "            baseline_kappas[ctr].append(cohen_kappa_score(y_pred, y_test))\n",
    "\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af44e38f-f74b-4d29-8886-db3bf9123eda",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting means and/or confidence intervals for (1) coefficients of linear model and (2) evaluation metric \n",
    "\n",
    "# Coefficients of model\n",
    "mean_coefs = [sum(coefficients[index]) / n_repeats for index in range(8)]\n",
    "\n",
    "# Evaluation metric\n",
    "mean_kappas = [sum(kappas[index]) / n_repeats for index in range(8)]\n",
    "mean_baseline_kappas = [sum(baseline_kappas[index]) / n_repeats for index in range(8)]\n",
    "\n",
    "# Formatted (for presentation) confidence intervals for the evaluation metric \n",
    "kappas_with_confidence = [\"{:.2f} \\u00B1 {:.2f}\".format(x,y) for x, y \n",
    "                              in zip(mean_kappas, [1.96 * stdev(x) / n_repeats ** 0.5 for x in kappas])]\n",
    "baseline_kappas_with_confidence = [\"{:.2f} \\u00B1 {:.2f}\".format(x,y) for x, y in\n",
    "                                   zip(mean_baseline_kappas, [1.96 * stdev(x) / n_repeats ** 0.5  for x in baseline_kappas])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f6f0dea2-152b-4d66-8119-aca16f5711f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0f154_row0_col0, #T_0f154_row0_col1, #T_0f154_row0_col2, #T_0f154_row0_col3, #T_0f154_row0_col4, #T_0f154_row0_col5, #T_0f154_row0_col6, #T_0f154_row1_col0, #T_0f154_row1_col1, #T_0f154_row1_col2, #T_0f154_row1_col3, #T_0f154_row1_col4, #T_0f154_row1_col5, #T_0f154_row1_col6, #T_0f154_row2_col0, #T_0f154_row2_col1, #T_0f154_row2_col2, #T_0f154_row2_col3, #T_0f154_row2_col4, #T_0f154_row2_col5, #T_0f154_row2_col6 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_0f154_row3_col0, #T_0f154_row3_col1, #T_0f154_row3_col2, #T_0f154_row3_col3, #T_0f154_row3_col4, #T_0f154_row3_col5, #T_0f154_row3_col6 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "#T_0f154_row4_col0, #T_0f154_row4_col1, #T_0f154_row4_col2, #T_0f154_row4_col3, #T_0f154_row4_col4, #T_0f154_row4_col5, #T_0f154_row4_col6 {\n",
       "  background-color: lightgray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0f154_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col1\" >Kappa (95331)</th>\n",
       "      <th class=\"col_heading level0 col2\" >RookDiff</th>\n",
       "      <th class=\"col_heading level0 col3\" >KnightDiff</th>\n",
       "      <th class=\"col_heading level0 col4\" >BishopDiff</th>\n",
       "      <th class=\"col_heading level0 col5\" >PawnDiff</th>\n",
       "      <th class=\"col_heading level0 col6\" >QueenDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0f154_level0_row0\" class=\"row_heading level0 row0\" >Amateur Midgame</th>\n",
       "      <td id=\"T_0f154_row0_col0\" class=\"data row0 col0\" >0.36 ± 0.02</td>\n",
       "      <td id=\"T_0f154_row0_col1\" class=\"data row0 col1\" >0.35 ± 0.02</td>\n",
       "      <td id=\"T_0f154_row0_col2\" class=\"data row0 col2\" >5.000000</td>\n",
       "      <td id=\"T_0f154_row0_col3\" class=\"data row0 col3\" >3.848639</td>\n",
       "      <td id=\"T_0f154_row0_col4\" class=\"data row0 col4\" >4.054197</td>\n",
       "      <td id=\"T_0f154_row0_col5\" class=\"data row0 col5\" >1.523413</td>\n",
       "      <td id=\"T_0f154_row0_col6\" class=\"data row0 col6\" >7.507990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f154_level0_row1\" class=\"row_heading level0 row1\" >Amateur Endgame</th>\n",
       "      <td id=\"T_0f154_row1_col0\" class=\"data row1 col0\" >0.51 ± 0.02</td>\n",
       "      <td id=\"T_0f154_row1_col1\" class=\"data row1 col1\" >0.51 ± 0.02</td>\n",
       "      <td id=\"T_0f154_row1_col2\" class=\"data row1 col2\" >5.000000</td>\n",
       "      <td id=\"T_0f154_row1_col3\" class=\"data row1 col3\" >3.185326</td>\n",
       "      <td id=\"T_0f154_row1_col4\" class=\"data row1 col4\" >3.676569</td>\n",
       "      <td id=\"T_0f154_row1_col5\" class=\"data row1 col5\" >1.232455</td>\n",
       "      <td id=\"T_0f154_row1_col6\" class=\"data row1 col6\" >7.222444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f154_level0_row2\" class=\"row_heading level0 row2\" >Expert Midgame</th>\n",
       "      <td id=\"T_0f154_row2_col0\" class=\"data row2 col0\" >0.19 ± 0.01</td>\n",
       "      <td id=\"T_0f154_row2_col1\" class=\"data row2 col1\" >0.18 ± 0.01</td>\n",
       "      <td id=\"T_0f154_row2_col2\" class=\"data row2 col2\" >5.000000</td>\n",
       "      <td id=\"T_0f154_row2_col3\" class=\"data row2 col3\" >2.185907</td>\n",
       "      <td id=\"T_0f154_row2_col4\" class=\"data row2 col4\" >4.302808</td>\n",
       "      <td id=\"T_0f154_row2_col5\" class=\"data row2 col5\" >4.619162</td>\n",
       "      <td id=\"T_0f154_row2_col6\" class=\"data row2 col6\" >3.943260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f154_level0_row3\" class=\"row_heading level0 row3\" >Expert Endgame</th>\n",
       "      <td id=\"T_0f154_row3_col0\" class=\"data row3 col0\" >0.37 ± 0.00</td>\n",
       "      <td id=\"T_0f154_row3_col1\" class=\"data row3 col1\" >0.44 ± 0.01</td>\n",
       "      <td id=\"T_0f154_row3_col2\" class=\"data row3 col2\" >5.000000</td>\n",
       "      <td id=\"T_0f154_row3_col3\" class=\"data row3 col3\" >2.720785</td>\n",
       "      <td id=\"T_0f154_row3_col4\" class=\"data row3 col4\" >3.336074</td>\n",
       "      <td id=\"T_0f154_row3_col5\" class=\"data row3 col5\" >3.124520</td>\n",
       "      <td id=\"T_0f154_row3_col6\" class=\"data row3 col6\" >4.193291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f154_level0_row4\" class=\"row_heading level0 row4\" >95331 values </th>\n",
       "      <td id=\"T_0f154_row4_col0\" class=\"data row4 col0\" ></td>\n",
       "      <td id=\"T_0f154_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_0f154_row4_col2\" class=\"data row4 col2\" >5.000000</td>\n",
       "      <td id=\"T_0f154_row4_col3\" class=\"data row4 col3\" >3.000000</td>\n",
       "      <td id=\"T_0f154_row4_col4\" class=\"data row4 col4\" >3.000000</td>\n",
       "      <td id=\"T_0f154_row4_col5\" class=\"data row4 col5\" >1.000000</td>\n",
       "      <td id=\"T_0f154_row4_col6\" class=\"data row4 col6\" >9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x183b35b50>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Amateur Midgame\", \"Amateur Endgame\", \"Expert Midgame\", \"Expert Endgame\"]\n",
    "\n",
    "PiecesOnlyResult = pd.concat([\n",
    "    pd.DataFrame(kappas_with_confidence[:4], columns = [\"Kappa\"]), \n",
    "    pd.DataFrame(baseline_kappas_with_confidence[:4], columns = [\"Kappa (95331)\"]), \n",
    "    pd.DataFrame([mean_coefs[i] * 5 / mean_coefs[i][0] for i in range(4)], columns = pieces_cols)\n",
    "          ], axis = 1)\n",
    "PiecesOnlyResult.index = labels\n",
    "\n",
    "def highlight_greater(row):\n",
    "    kappa = row[\"Kappa\"].split(\"\\u00B1\")[0]\n",
    "    kappa95331 = row[(\"Kappa (95331)\") if \"Kappa (95331)\" in row else \"Kappa (Shannon 1949)\"].split('\\u00B1')[0] \n",
    "    if row[\"Kappa\"] == \"\": \n",
    "        color = \"lightgray\"\n",
    "    elif float(kappa) < float(kappa95331) - 0.02:\n",
    "        color = \"lightcoral\"\n",
    "    elif float(kappa) > float(kappa95331) + 0.02:\n",
    "        color = \"lightgreen\"\n",
    "    else:\n",
    "        color = \"white\"\n",
    "    background = ['background-color: {}'.format(color) for _ in row]\n",
    "    return background\n",
    "\n",
    "Score95331 = pd.DataFrame([[\"\", \"\", 5, 3, 3, 1, 9]], \n",
    "             index = [\"95331 values \"], \n",
    "             columns = PiecesOnlyResult.columns)\n",
    "\n",
    "pd.concat([PiecesOnlyResult, Score95331], axis = 0).style.apply(highlight_greater, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "04328cb6-0aba-42f6-9a62-bc207854febf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e5514_row0_col0, #T_e5514_row0_col1, #T_e5514_row0_col2, #T_e5514_row0_col3, #T_e5514_row0_col4, #T_e5514_row0_col5, #T_e5514_row0_col6, #T_e5514_row0_col7, #T_e5514_row0_col8, #T_e5514_row0_col9, #T_e5514_row0_col10, #T_e5514_row1_col0, #T_e5514_row1_col1, #T_e5514_row1_col2, #T_e5514_row1_col3, #T_e5514_row1_col4, #T_e5514_row1_col5, #T_e5514_row1_col6, #T_e5514_row1_col7, #T_e5514_row1_col8, #T_e5514_row1_col9, #T_e5514_row1_col10 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_e5514_row2_col0, #T_e5514_row2_col1, #T_e5514_row2_col2, #T_e5514_row2_col3, #T_e5514_row2_col4, #T_e5514_row2_col5, #T_e5514_row2_col6, #T_e5514_row2_col7, #T_e5514_row2_col8, #T_e5514_row2_col9, #T_e5514_row2_col10, #T_e5514_row3_col0, #T_e5514_row3_col1, #T_e5514_row3_col2, #T_e5514_row3_col3, #T_e5514_row3_col4, #T_e5514_row3_col5, #T_e5514_row3_col6, #T_e5514_row3_col7, #T_e5514_row3_col8, #T_e5514_row3_col9, #T_e5514_row3_col10 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_e5514_row4_col0, #T_e5514_row4_col1, #T_e5514_row4_col2, #T_e5514_row4_col3, #T_e5514_row4_col4, #T_e5514_row4_col5, #T_e5514_row4_col6, #T_e5514_row4_col7, #T_e5514_row4_col8, #T_e5514_row4_col9, #T_e5514_row4_col10 {\n",
       "  background-color: lightgray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e5514_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col1\" >Kappa (Shannon 1949)</th>\n",
       "      <th class=\"col_heading level0 col2\" >RookDiff</th>\n",
       "      <th class=\"col_heading level0 col3\" >KnightDiff</th>\n",
       "      <th class=\"col_heading level0 col4\" >BishopDiff</th>\n",
       "      <th class=\"col_heading level0 col5\" >PawnDiff</th>\n",
       "      <th class=\"col_heading level0 col6\" >QueenDiff</th>\n",
       "      <th class=\"col_heading level0 col7\" >BlockedPawnDiff</th>\n",
       "      <th class=\"col_heading level0 col8\" >IsolatedPawnDiff</th>\n",
       "      <th class=\"col_heading level0 col9\" >DoublePawnDiff</th>\n",
       "      <th class=\"col_heading level0 col10\" >MobilityDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e5514_level0_row0\" class=\"row_heading level0 row0\" >Amateur Midgame</th>\n",
       "      <td id=\"T_e5514_row0_col0\" class=\"data row0 col0\" >0.36 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row0_col1\" class=\"data row0 col1\" >0.36 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row0_col2\" class=\"data row0 col2\" >5.000000</td>\n",
       "      <td id=\"T_e5514_row0_col3\" class=\"data row0 col3\" >3.843010</td>\n",
       "      <td id=\"T_e5514_row0_col4\" class=\"data row0 col4\" >4.135910</td>\n",
       "      <td id=\"T_e5514_row0_col5\" class=\"data row0 col5\" >1.512344</td>\n",
       "      <td id=\"T_e5514_row0_col6\" class=\"data row0 col6\" >7.224041</td>\n",
       "      <td id=\"T_e5514_row0_col7\" class=\"data row0 col7\" >-0.426983</td>\n",
       "      <td id=\"T_e5514_row0_col8\" class=\"data row0 col8\" >-0.291868</td>\n",
       "      <td id=\"T_e5514_row0_col9\" class=\"data row0 col9\" >-0.128834</td>\n",
       "      <td id=\"T_e5514_row0_col10\" class=\"data row0 col10\" >0.114810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5514_level0_row1\" class=\"row_heading level0 row1\" >Amateur Endgame</th>\n",
       "      <td id=\"T_e5514_row1_col0\" class=\"data row1 col0\" >0.51 ± 0.03</td>\n",
       "      <td id=\"T_e5514_row1_col1\" class=\"data row1 col1\" >0.51 ± 0.03</td>\n",
       "      <td id=\"T_e5514_row1_col2\" class=\"data row1 col2\" >5.000000</td>\n",
       "      <td id=\"T_e5514_row1_col3\" class=\"data row1 col3\" >3.215652</td>\n",
       "      <td id=\"T_e5514_row1_col4\" class=\"data row1 col4\" >3.784472</td>\n",
       "      <td id=\"T_e5514_row1_col5\" class=\"data row1 col5\" >1.416467</td>\n",
       "      <td id=\"T_e5514_row1_col6\" class=\"data row1 col6\" >6.829518</td>\n",
       "      <td id=\"T_e5514_row1_col7\" class=\"data row1 col7\" >-0.378407</td>\n",
       "      <td id=\"T_e5514_row1_col8\" class=\"data row1 col8\" >-0.217435</td>\n",
       "      <td id=\"T_e5514_row1_col9\" class=\"data row1 col9\" >-0.105707</td>\n",
       "      <td id=\"T_e5514_row1_col10\" class=\"data row1 col10\" >0.114424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5514_level0_row2\" class=\"row_heading level0 row2\" >Expert Midgame</th>\n",
       "      <td id=\"T_e5514_row2_col0\" class=\"data row2 col0\" >0.27 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row2_col1\" class=\"data row2 col1\" >0.23 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row2_col2\" class=\"data row2 col2\" >5.000000</td>\n",
       "      <td id=\"T_e5514_row2_col3\" class=\"data row2 col3\" >2.088699</td>\n",
       "      <td id=\"T_e5514_row2_col4\" class=\"data row2 col4\" >4.524157</td>\n",
       "      <td id=\"T_e5514_row2_col5\" class=\"data row2 col5\" >4.908509</td>\n",
       "      <td id=\"T_e5514_row2_col6\" class=\"data row2 col6\" >3.279411</td>\n",
       "      <td id=\"T_e5514_row2_col7\" class=\"data row2 col7\" >-1.678651</td>\n",
       "      <td id=\"T_e5514_row2_col8\" class=\"data row2 col8\" >-0.844513</td>\n",
       "      <td id=\"T_e5514_row2_col9\" class=\"data row2 col9\" >-0.099627</td>\n",
       "      <td id=\"T_e5514_row2_col10\" class=\"data row2 col10\" >0.279509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5514_level0_row3\" class=\"row_heading level0 row3\" >Expert Endgame</th>\n",
       "      <td id=\"T_e5514_row3_col0\" class=\"data row3 col0\" >0.46 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row3_col1\" class=\"data row3 col1\" >0.41 ± 0.01</td>\n",
       "      <td id=\"T_e5514_row3_col2\" class=\"data row3 col2\" >5.000000</td>\n",
       "      <td id=\"T_e5514_row3_col3\" class=\"data row3 col3\" >2.704622</td>\n",
       "      <td id=\"T_e5514_row3_col4\" class=\"data row3 col4\" >3.281451</td>\n",
       "      <td id=\"T_e5514_row3_col5\" class=\"data row3 col5\" >3.607261</td>\n",
       "      <td id=\"T_e5514_row3_col6\" class=\"data row3 col6\" >3.624072</td>\n",
       "      <td id=\"T_e5514_row3_col7\" class=\"data row3 col7\" >-0.729117</td>\n",
       "      <td id=\"T_e5514_row3_col8\" class=\"data row3 col8\" >-0.278615</td>\n",
       "      <td id=\"T_e5514_row3_col9\" class=\"data row3 col9\" >-0.490474</td>\n",
       "      <td id=\"T_e5514_row3_col10\" class=\"data row3 col10\" >0.221070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5514_level0_row4\" class=\"row_heading level0 row4\" >Shannon 1949</th>\n",
       "      <td id=\"T_e5514_row4_col0\" class=\"data row4 col0\" ></td>\n",
       "      <td id=\"T_e5514_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_e5514_row4_col2\" class=\"data row4 col2\" >5.000000</td>\n",
       "      <td id=\"T_e5514_row4_col3\" class=\"data row4 col3\" >3.000000</td>\n",
       "      <td id=\"T_e5514_row4_col4\" class=\"data row4 col4\" >3.000000</td>\n",
       "      <td id=\"T_e5514_row4_col5\" class=\"data row4 col5\" >1.000000</td>\n",
       "      <td id=\"T_e5514_row4_col6\" class=\"data row4 col6\" >9.000000</td>\n",
       "      <td id=\"T_e5514_row4_col7\" class=\"data row4 col7\" >-0.500000</td>\n",
       "      <td id=\"T_e5514_row4_col8\" class=\"data row4 col8\" >-0.500000</td>\n",
       "      <td id=\"T_e5514_row4_col9\" class=\"data row4 col9\" >-0.500000</td>\n",
       "      <td id=\"T_e5514_row4_col10\" class=\"data row4 col10\" >0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x183b56730>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllFeaturesResult = pd.concat([\n",
    "    pd.DataFrame(kappas_with_confidence[4:8], columns = [\"Kappa\"]), \n",
    "    pd.DataFrame(baseline_kappas_with_confidence[4:8], columns = [\"Kappa (Shannon 1949)\"]), \n",
    "    pd.DataFrame([mean_coefs[i] * 5 / mean_coefs[i][0] for i in range(4,8)], columns = pieces_cols + bad_pawns_cols + [\"MobilityDiff\"])\n",
    "          ], axis = 1)\n",
    "AllFeaturesResult.index = labels\n",
    "\n",
    "Shannon1949 = pd.DataFrame([[\"\", \"\", 5, 3, 3, 1, 9, -0.5, -0.5, -0.5, 0.1]], \n",
    "             index = [\"Shannon 1949\"], \n",
    "             columns = AllFeaturesResult.columns)\n",
    "\n",
    "pd.concat([AllFeaturesResult, Shannon1949], axis = 0).style.apply(highlight_greater, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26840430-dbc8-4b98-a095-b9493efc2939",
   "metadata": {},
   "source": [
    "In each table, 'Kappa' is the evaluation metric result, having fitted Logistic Regression on the features listed in the columns. 'Kappa (95331)' in the first table is the Kappa score produced from setting the Logistic Regression coefficients equal to the traditional piece scores (listed in the row '95331 values'). 'Kappa (Shannon 1949)' in the second table is the Kappa score produced from the same procedure, but using the scores listed in the row 'Shannon 1949'. All values for kappa are expressed with their 95% confidence intervals.\n",
    "\n",
    "In the first table, our logistic regression does no better than the 95331 values. In the red row, 'Expert Endgame', it even does worse! This is an unfortunate side effect of the fact that Logistic Regression is working on optimizing its loss function (binary cross entropy), and minimizing this loss function does not have the same effect as maximizing the kappa score, or any other typical evaluation metric. Support vector classifier, which uses a hinge loss function, also fails in this regard. No amount of hyperparameter tuning on my part seems to resolve this issue. \n",
    "\n",
    "In the second table, our logistic regression does significantly better than Shannon 1949 values, for the expert games only. Given this result, we can now try to make sense of the values given for each coefficient. These values are scaled so that 'RookDiff' is assigned to the value 5. The greatest anomalies that result are: the pawn is worth much more than 1, and the queen has extremely low point value compared to what we'd expect. The queen even has a smaller value than the rook, even though it is strictly more powerful. \n",
    "\n",
    "It is interesting to think that the coefficients needed to *predict* victory, in an actual game, are not necessarily the same thing as the coefficients than can be used to *guide action* for winning the game. It would be ridiculous for someone to see these values and decide to sacrifice a queen for a rook. Similarly, if we were to plug my coefficients into the values for an evaluation function used to run a chess engine, the chess engine would lose every match. But our coefficients are telling us that, *given* a human, expert chess player has chosen to play in such a way that they have 0 queens and 1 rook, they are likely better off than if they had 1 queen and 0 rooks. In other words, an experienced chess player will never sacrifice a queen unless it gains them compensating benefits in other ways. In the specific context of two expert players in a tournament setting, I could use the coefficients of my model -which treat a rook as more valuable than a queen- to make a better prediction for who wins, than if I were to use more intuitive, sensible values that treat a queen as more valuable than a rook. \n",
    "\n",
    "One last note of interest is that including the features for bad pawns and mobility causes the kappa values for expert games to increase drastically, even though the kappa scores for amateur games stay the same. It should be expected that amateur players cannot make as strong use of their positions to win a game, and so the number of pieces they have is the dominating predictor in who wins. It should also be expected that experts should be able to leverage any advantage in position to win despite fewer pieces. We can see that the trend in our evaluation metric scores reflects these expectations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60eee7-13dc-4159-be43-93eff3ae6e58",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Feature Engineering (Part 2) </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a8756-d5fd-42cd-91a8-a6f88b4f4f5e",
   "metadata": {},
   "source": [
    "In the last section, I used a restricted number of features and used logistic regression so that I could easily interpret the resulting fitted coefficients. However, I can create a much better performing model by not imposing these restrictions. In this section, I engineer several more features that can be used to predict victory. In the next section, I'll use XGBClassifier to do the predictions on the full dataset. \n",
    "\n",
    "The features I make in this section are:\n",
    "* *Two Bishops*: whether or not each player has two bishops. \n",
    "* *Two Knights*: whether or not each player has two knights. \n",
    "* *Number of 'Advanced' Pawns*: how many pawns each player has, that have advanced to the opponent's side of the board\n",
    "* *Number of 'Advanced' Pieces*: how many pieces each player has, excluding pawns, that have advanced to the opponent's side of the board\n",
    "* *Center Control*: number of pieces each player has in the central four squares of the board. I ultimately remove this feature during modelling because it reduces performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9659f1e5-d4f5-4cfe-bdb2-6e1cb261fb82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = [AmateurMidgameData, AmateurEndgameData, ExpertMidgameData, ExpertEndgameData]\n",
    "\n",
    "for df in dfs:\n",
    "    # Two-Bishops or Two-Knights\n",
    "    df[\"TwoBishops_White\"] = df.FEN.apply(lambda s: 1 if (s.count('B') == 2) else 0)\n",
    "    df[\"TwoBishops_Black\"] = df.FEN.apply(lambda s: 1 if (s.count('b') == 2) else 0)\n",
    "    df[\"TwoKnights_White\"] = df.FEN.apply(lambda s: 1 if (s.count('N') == 2) else 0)\n",
    "    df[\"TwoKnights_Black\"] = df.FEN.apply(lambda s: 1 if (s.count('n') == 2) else 0)\n",
    "    # Number of pawns moved past mid-point of board\n",
    "    df[\"AdvancedPawns_White\"] = df.FEN.apply(lambda s: ''.join(simplify_FEN(s).split('/')[:4]).count('P')) \n",
    "    df[\"AdvancedPawns_Black\"] = df.FEN.apply(lambda s: ''.join(simplify_FEN(s).split('/')[4:]).count('p')) \n",
    "    # Number of pieces (*excluding* pawns) moved past mid-point of board\n",
    "    df[\"AdvancedPieces_White\"] = df.FEN.apply(lambda s: len([char for char in\\\n",
    "                                                             ''.join(simplify_FEN(s).split('/')[:4]).replace('P', '')\\\n",
    "                                                             if char.isupper()]))\n",
    "    df[\"AdvancedPieces_Black\"] = df.FEN.apply(lambda s: len([char for char in\\\n",
    "                                                         ''.join(simplify_FEN(s).split('/')[4:]).replace('p', '')\\\n",
    "                                                         if char.islower()]))\n",
    "    # Center control, measured by how many pieces are in center 4 squares (or extended center of 16 squares) causes worse performance overall \n",
    "    # # Center control --- Number of pieces in center 4 squares\n",
    "    # df[\"CenterControl_White\"] = df.FEN.apply(lambda s: len([char for char in\\\n",
    "    #                                                     ''.join(list(np.array(convert_FEN_to_Matrix(s))[3:5, 3:5].flatten()))\\\n",
    "    #                                                     if char.isupper()]))\n",
    "    # df[\"CenterControl_Black\"] = df.FEN.apply(lambda s: len([char for char in\\\n",
    "    #                                                     ''.join(list(np.array(convert_FEN_to_Matrix(s))[3:5, 3:5].flatten()))\\\n",
    "    #                                                     if char.islower()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277e0ea-331b-4ddf-9e69-95d9d88ce37e",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Game Result Prediction Using XGBoost </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272223f-e950-4721-b6ef-741dbf10dd10",
   "metadata": {},
   "source": [
    "In this section, I use all my engineered features and XGBoost to make a better classification model for predicting victory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "648e8f5e-4850-4c48-b7e4-a2bb1ccb2d8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning run 1 of 4\n",
      "Beginning run 2 of 4\n",
      "Beginning run 3 of 4\n",
      "Beginning run 4 of 4\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "\n",
    "# Storage for logistic regression fitting parameters, and for evaluation metrics\n",
    "coefficients = [[] for _ in range(4)]\n",
    "kappas = [[] for _ in range(4)]\n",
    "baseline_kappas = [[] for _ in range(4)]\n",
    "\n",
    "# Fit 4 sets of data, with 2 different feature spaces each\n",
    "for ctr, data in enumerate(dfs):\n",
    "    print('Beginning run {} of 4'.format(ctr + 1))\n",
    "\n",
    "    # Get X and y, training and test\n",
    "    X = data.drop([\"Turn\", \"FEN\", \"PGN\", \"Result\"], axis = 1)\n",
    "    y = data[\"Result\"]\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify = y)\n",
    "\n",
    "        # Fit model and Make predictions \n",
    "        evalset = [(X_train, y_train), (X_test, y_test)]\n",
    "        model = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "            # n_estimators = 100 (default) is good. \n",
    "            # reg_lambda: tuning up is bad. tuning down has very minimal change. \n",
    "        \n",
    "        model.fit(X_train, y_train, eval_metric='auc', eval_set=evalset, verbose = 0)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save fevaluation metric\n",
    "        kappas[ctr].append(cohen_kappa_score(y_pred, y_test))\n",
    "    \n",
    "# Evaluation metric -- confidence intervals\n",
    "mean_kappas = [sum(kappas[index]) / n_repeats for index in range(4)]\n",
    "kappas_with_confidence = [\"{:.2f} \\u00B1 {:.3f}\".format(x,y) for x, y \n",
    "                              in zip(mean_kappas, [1.96 * stdev(x) / n_repeats ** 0.5 for x in kappas])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ab599-b0f2-4157-ae4b-a6aa83c2ea58",
   "metadata": {},
   "source": [
    "I used plots of training and testing validation scores, in the hidden code block below, to guide whether I tuned any hyperparameters in XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1c799551-97a5-4b32-9109-539ed6fda775",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.evals_result()\n",
    "plt.plot(results['validation_0']['auc'], label='train')\n",
    "plt.plot(results['validation_1']['auc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ae4cea90-5bd8-4c12-9261-0168122aef54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Amateur Midgame, kappa score is 0.33 ± 0.025\n",
      "For Amateur Endgame, kappa score is 0.51 ± 0.026\n",
      "For Expert Midgame, kappa score is 0.35 ± 0.003\n",
      "For Expert Endgame, kappa score is 0.61 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Amateur Midgame\", \"Amateur Endgame\", \"Expert Midgame\", \"Expert Endgame\"]\n",
    "for i, kappa in enumerate(kappas_with_confidence):\n",
    "    print('For {}, kappa score is {}'.format(labels[i], kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e3609-530c-4770-abce-3f3f32784ef7",
   "metadata": {},
   "source": [
    "For the expert midgame and expert endgame, these are much better performances than we were seeing earlier. Using XGBClassifier and adding many more features each improved the kappa scores by several percent. \n",
    "\n",
    "For amateur games, the performance is no better than before, when we used logistic regression and very few features. As discussed earlier, the result of amateur games seems to depend only on which player has more pieces. Because the only predictive feature is the number of pieces each player has, adding position-related features tends to distract and clutter training with irrelevant information, which reduces kappa values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
