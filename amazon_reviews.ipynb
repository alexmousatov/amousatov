{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520abbd9-423c-4792-9889-d88b10afd432",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:120%;text-align:center;border-radius:10px 10px;\">Amazon Product Quality Report</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c7b66-8532-4b22-9838-2d4742dfd38a",
   "metadata": {},
   "source": [
    "I scrape and clean Amazon review and rating data for multiple products, with the aim of creating a concise, customer-friendly report on the product. \n",
    "* I identify the probable presence of unreliable product quality and/or fraudulent reviews, using a chi-squared test. \n",
    "* I extract keywords used by happy versus unhappy uncustomers, with an emphasis on keywords that express concrete features of the product, while excluding uninformative sentimental keywords. \n",
    "* I create a concise, balanced report on product pros and cons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba4db2-70aa-4476-8645-d471659c34ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Importing Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "8f1afbfa-aad4-4137-a5e4-c04b279a9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "# standard libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# for file management\n",
    "import os \n",
    "\n",
    "# for data scraping\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from user_agent import generate_user_agent\n",
    "\n",
    "# for formatting and cleaning\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# language \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# statistics\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e14a6-caa7-4612-b1ee-cf08bb77139d",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Scraper for Amazon Product Reviews</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a9890-3e2f-4843-a44a-c76d0f20422a",
   "metadata": {},
   "source": [
    "I scraped data from Amazon reviews for four different Amazon products. \n",
    "\n",
    "The code for the scraping is below. However, at least for me, it no longer works. Amazon now detects me as a bot and blocks all access. I temporarily resolved this problem by attaching a randomly generated user agent to each of my requests, but this doesn't work anymore. I've given up, for now, on getting past their bot detection. Therefore I only have reviews from the four products I looked at before my scraper stopped working.  \n",
    "\n",
    "The code below defines the Amazon review scraper. \n",
    "* The function 'get_soup' takes as input the URL of a webpage, and retrieves the HTML. \n",
    "* The function 'convert_Amazon_product_to_reviews' takes as input the URL of any product page on Amazon, and converts it to the URL containing the first page of all product reviews. This URL ends in 'pageNumber=', so that moving through the pages of reviews simply involves adding a number, 1+, to the end of the string. \n",
    "* The function 'extract_Amazon_reviews' takes as input the main product page URL and returns a dataframe including: the review title, name of reviewer, star rating, where and when the review was made, the specific product style purchased, whether the review arises from a 'verified' purchase, the review text, and the number of helpful votes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b9f48eb4-b747-49e3-b5d1-8153466ae91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_soup(URL: str):\n",
    "    s = requests.Session()\n",
    "    \n",
    "    # Random user agent.\n",
    "    user_agent = generate_user_agent()\n",
    "    headers = {'User-Agent': user_agent, 'Accept-Language': 'en-US, en;q=0.5'}        \n",
    "\n",
    "    # Get soup \n",
    "    webpage = s.get(URL, headers = headers)\n",
    "    soup = BeautifulSoup(webpage.text, 'lxml')\n",
    "    \n",
    "    # Return error message\n",
    "    if (\"Sorry, we just need to make sure you\\'re not a robot\" in str(soup)) or (\"To discuss automated access\" in str(soup)): # Part of error messages about bots\n",
    "        print('Error. Amazon blocked access.') \n",
    "        return None\n",
    "\n",
    "    # Return soup\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8a13ac17-1e43-4535-bc9f-ac68e0e903fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error. Amazon blocked access.\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.amazon.com/Software-Design-Flexibility-Programming-Yourself-ebook/dp/B089423GC6/?pf_rd_r=V3Y43HK5TFK9VWA30XD6&pf_rd_p=935389f8-611a-4123-b867-b2d567ba3a96&pd_rd_r=7385a253-360e-4f17-83a6-03adefa6787f&pd_rd_w=Qe2rk&pd_rd_wg=P0a9Y&ref_=pd_gw_bmx_gp_1g4a5hlo'\n",
    "get_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25213b95-9ee8-469f-98a3-6da0203d4ba2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_Amazon_product_to_reviews(URL: str):\n",
    "    return URL.replace('/dp', '/product-reviews').split('ref=')[0] + 'ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54e836e7-a096-4f9d-8b09-efbacc4996f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_Amazon_reviews(URL: str, page_no: int):\n",
    "    # Get soup\n",
    "    URL = convert_Amazon_product_to_reviews(URL)\n",
    "    soup = get_soup(URL + str(page_no))\n",
    "    if not soup:\n",
    "        return \n",
    "    \n",
    "    # Extract sub-soup with all review information \n",
    "    reviewSection = soup.find(\"div\", attrs = {\"id\": \"cm_cr-review_list\", \"class\" : \"a-section a-spacing-none review-views celwidget\"})\n",
    "    if not reviewSection: # if no review section: stop!\n",
    "        return pd.DataFrame()\n",
    "    allReviews = reviewSection.find_all(\"div\", attrs = {\"data-hook\" : \"review\"})\n",
    "    if not allReviews: # if no reviews: stop!\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Review Title - can appear under two possible tags \n",
    "    reviewTitle = []\n",
    "    for review in allReviews:\n",
    "        x = review.find(\"a\", attrs = {\"data-hook\" : \"review-title\"})\n",
    "        if x:\n",
    "            reviewTitle.append(x.span.string)\n",
    "        else:\n",
    "            reviewTitle.append(review.find(\"span\", attrs = {\"data-hook\" : \"review-title\"}).span.string)\n",
    "\n",
    "    # Reviewer Name\n",
    "    reviewerNames = [review.find(\"span\", attrs = {\"class\": \"a-profile-name\"}).string for review in allReviews]\n",
    "    \n",
    "    # Star Rating\n",
    "    ratings = [int(float(review.find(\"span\", attrs = {\"class\": \"a-icon-alt\"}).string.split()[0])) for review in allReviews]\n",
    "    \n",
    "    # Where and When Review was Made\n",
    "    reviewPlaceDate = [review.find(\"span\", attrs = {\"data-hook\": \"review-date\"}).string.strip() for review in allReviews]\n",
    "    \n",
    "    # Product Style (if it exists)\n",
    "    productStyle = [review.find(\"a\", attrs = {\"data-hook\": \"format-strip\"}) for review in allReviews]\n",
    "    productStyle = [(x.string if x else None) for x in productStyle]\n",
    "    \n",
    "    # Verified Purchase\n",
    "    reviewType = [review.find(\"span\", attrs = {\"data-hook\": \"avp-badge\"}) for review in allReviews]\n",
    "    reviewType = [(x.string if x is not None else x) for x in reviewType]\n",
    "\n",
    "    # Review Text\n",
    "    reviewText = [review.find(\"span\", attrs = {\"data-hook\": \"review-body\"}).span for review in allReviews]\n",
    "    reviewText = [(review.contents if review else \"\") for review in reviewText] # handles possibility of empty review text\n",
    "    reviewText = [(' '.join(list(filter(None, [x.string for x in review]))).replace('\\n', ' ').strip() if review != \"\" else \"\") for review in reviewText]\n",
    "\n",
    "    # Helpful Votes \n",
    "    helpfulVotes = [review.find(\"span\", attrs = {\"data-hook\" : \"helpful-vote-statement\"}) for review in allReviews]\n",
    "    helpfulVotes = [(x.string.split()[0] if x is not None else x) for x in helpfulVotes]\n",
    "\n",
    "    # Make Dataframe \n",
    "    columns = [\"Name\", \"Rating\", \"ReviewTitle\", \"PlaceDate\", \"ProductStyle\", \"IsVerified\", \"ReviewText\", \"HelpfulVotes\"]\n",
    "    data = pd.DataFrame(list(zip(reviewerNames, ratings, reviewTitle, reviewPlaceDate, productStyle, reviewType, reviewText, helpfulVotes)), \n",
    "                columns = columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db1bdd-56eb-4f14-89dd-e971c267100a",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Data scraping and cleaning</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593893e5-7677-4831-ae79-e88b2e5789e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this section, I scrape, clean, and save data for four miscellaneous, popular products.\n",
    "* Pampers -- Baby Wipes: https://www.amazon.com/Choose-your-count-Sensitive-Hypoallergenic/dp/B079V67BFW/ref=cm_cr_arp_d_product_top?ie=UTF8\n",
    "* FangTian -- N95 Masks: https://www.amazon.com/FANGTIAN-Particulate-Respirators-Protective-TC-84A-7861/dp/B087Z7N4XF/ref=cm_cr_arp_d_product_top?ie=UTF8\n",
    "* Nature's Nutrition -- Turmeric Supplements: https://www.amazon.com/Curcuminoids-Absorption-Anti-Inflammatory-Natures-Nutrition/dp/B06X9T1Y3F/ref=cm_cr_arp_d_product_top?ie=UTF8\n",
    "* Nike -- Men's Sneakers: https://www.amazon.com/Nike-Mens-Monarch-Cross-Trainer/dp/B07JQKM2SP/ref=cm_cr_arp_d_product_top?ie=UTF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b03d9579-0de1-415d-86a0-b4bf3b4e0be3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample Product URLS \n",
    "URL_PampersWipes = \"https://www.amazon.com/Choose-your-count-Sensitive-Hypoallergenic/product-reviews/B079V67BFW/ \\\n",
    "    ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=\"\n",
    "URL_N95 = \"https://www.amazon.com/FANGTIAN-Particulate-Respirators-Protective-TC-84A-7861/product-reviews/B087Z7N4XF/   \\\n",
    "    ref=cm_cr_arp_d_paging_?btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\"\n",
    "URL_TurmericSupplement = \"https://www.amazon.com/Curcuminoids-Absorption-Anti-Inflammatory-Natures-Nutrition/product-reviews/B06X9T1Y3F/  \\\n",
    "    ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\"\n",
    "URL_Nike = \"https://www.amazon.com/Nike-Mens-Monarch-Cross-Trainer/product-reviews/B07JQKM2SP/ \\\n",
    "    ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\"\n",
    "\n",
    "Sample_URLS = {\"PampersWipes\": URL_PampersWipes, \"N95\": URL_N95, \"TurmericSupplement\": URL_TurmericSupplement, \"Nike\": URL_Nike}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e9db9819-18c5-49ed-a884-2d290241e42f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose product and maximum number of pages you want to check \n",
    "product = \"TurmericSupplement\"\n",
    "page_lim = 1000\n",
    "\n",
    "# Product Name \n",
    "URL_base = Sample_URLS[product]\n",
    "productName = get_soup(URL_base, 1).find(\"a\", attrs = {\"data-hook\" : \"product-link\"}).string\n",
    "\n",
    "# Initialize dataframe\n",
    "columns = [\"Name\", \"Rating\", \"ReviewTitle\", \"PlaceDate\", \"ProductStyle\", \"IsVerified\", \"ReviewText\", \"HelpfulVotes\"]\n",
    "data = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Fill out dataframe\n",
    "for page_no in range(1, page_lim):\n",
    "    # Extract reviews \n",
    "    page_data = extract_review_dataframe(page_no)\n",
    "    \n",
    "    # If no more reviews found: break. Otherwise, concatenate to our growing dataframe. \n",
    "    if page_data.empty: \n",
    "        break \n",
    "    data = pd.concat([data, page_data])\n",
    "    \n",
    "    # Status update \n",
    "    if page_no % 20 == 0: print(\"Currently at page number {}\".format(page_no))\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "# Reset index\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Replace 'PlaceDate' column with 'Place' and 'Date' columns \n",
    "for index in data.index:\n",
    "    placedate = data.loc[index, \"PlaceDate\"]\n",
    "    a, b = re.search('^Reviewed in ', placedate).span()\n",
    "    c, d = re.search(' on ', placedate).span()\n",
    "    place, date = placedate[b:c], placedate[d:]\n",
    "    data.loc[index, \"Place\"] = place\n",
    "    data.loc[index, \"Date\"] = date\n",
    "data.drop(\"PlaceDate\", axis = 1, inplace = True)\n",
    "\n",
    "# Label encode 'IsVerified' column\n",
    "data[\"IsVerified\"].replace({\"Verified Purchase\": 1, None: 0}, inplace = True)\n",
    "\n",
    "# Make 'HelpfulVotes' column an integer type \n",
    "data[\"HelpfulVotes\"].replace({'One': \"1\", None: \"0\"}, inplace = True)\n",
    "data[\"HelpfulVotes\"] = data.HelpfulVotes.str.replace(',', '').astype(int)\n",
    "\n",
    "# Make 'Date' column a datetime type \n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "\n",
    "# Add 'Year' and 'Month' columns \n",
    "data[\"Year\"] = data[\"Date\"].apply(lambda x: (x.year))\n",
    "data[\"Month\"] = data[\"Date\"].apply(lambda x: (x.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6ffb1654-31d2-4bb9-99f1-0da31fb4047c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save (or update) dataframe\n",
    "# filename = \"Data_\" + str(product) + \".csv\"\n",
    "# if os.path.exists(filename):\n",
    "#     os.remove(filename)\n",
    "# data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c906418-e911-4496-bdbf-bc810fd1fb23",
   "metadata": {},
   "source": [
    "See below an example of what our data looks like, for the Turmeric Supplements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7aa0fa46-11ee-4f53-bf10-20478b7da4f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ProductStyle</th>\n",
       "      <th>IsVerified</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>HelpfulVotes</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vagma</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT THE SAME</td>\n",
       "      <td>Size: 120 Count (Pack of 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>I've been ordering these turmeric pills for a ...</td>\n",
       "      <td>2595</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>1</td>\n",
       "      <td>White Capsules Mixed in with Turmeric??</td>\n",
       "      <td>Size: 180 Count (Pack of 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Was shocked to find white capsules mixed in wi...</td>\n",
       "      <td>1774</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>5</td>\n",
       "      <td>Love it.</td>\n",
       "      <td>Size: 180 Count (Pack of 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me begin with that I have a degree in biol...</td>\n",
       "      <td>1156</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathy Sneed</td>\n",
       "      <td>1</td>\n",
       "      <td>Beware</td>\n",
       "      <td>Size: 60 Count (Pack of 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>It worked get for arthritis but my husband had...</td>\n",
       "      <td>820</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny</td>\n",
       "      <td>1</td>\n",
       "      <td>Nausea and diarrhea</td>\n",
       "      <td>Size: 60 Count (Pack of 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>I took only 2 capsules instead of the 3 reccom...</td>\n",
       "      <td>614</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  Rating                              ReviewTitle  \\\n",
       "0            vagma       1                             NOT THE SAME   \n",
       "1  Amazon Customer       1  White Capsules Mixed in with Turmeric??   \n",
       "2  Amazon Customer       5                                 Love it.   \n",
       "3      Kathy Sneed       1                                   Beware   \n",
       "4           Johnny       1                      Nausea and diarrhea   \n",
       "\n",
       "                  ProductStyle  IsVerified  \\\n",
       "0  Size: 120 Count (Pack of 1)           1   \n",
       "1  Size: 180 Count (Pack of 1)           1   \n",
       "2  Size: 180 Count (Pack of 1)           1   \n",
       "3   Size: 60 Count (Pack of 1)           1   \n",
       "4   Size: 60 Count (Pack of 1)           1   \n",
       "\n",
       "                                          ReviewText  HelpfulVotes  \\\n",
       "0  I've been ordering these turmeric pills for a ...          2595   \n",
       "1  Was shocked to find white capsules mixed in wi...          1774   \n",
       "2  Let me begin with that I have a degree in biol...          1156   \n",
       "3  It worked get for arthritis but my husband had...           820   \n",
       "4  I took only 2 capsules instead of the 3 reccom...           614   \n",
       "\n",
       "               Place        Date  Year  Month  \n",
       "0  the United States  2018-09-19  2018      9  \n",
       "1  the United States  2019-05-16  2019      5  \n",
       "2  the United States  2018-08-18  2018      8  \n",
       "3  the United States  2018-10-05  2018     10  \n",
       "4  the United States  2019-05-01  2019      5  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data for desired product \n",
    "product = \"TurmericSupplement\" #N95, PampersWipes, TurmericSupplement, Nike\n",
    "filename = \"Data_\" + str(product) + \".csv\"\n",
    "data = pd.read_csv(filename, index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b53df5-cee4-4939-925e-e53687a5e86a",
   "metadata": {},
   "source": [
    "These are the number of reviews we collected for each product. For products with over 5000 reviews, I only collected the first 5000, most recent reviews. For all products, I collected every review made within the year of 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a793e5ad-3968-45b3-ac00-b115f82537fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1319 reviews for the product PampersWipes\n",
      "We have 5000 reviews for the product Nike\n",
      "We have 5000 reviews for the product TurmericSupplement\n",
      "We have 1213 reviews for the product N95\n"
     ]
    }
   ],
   "source": [
    "for product in [\"PampersWipes\", \"Nike\", \"TurmericSupplement\", \"N95\"]:\n",
    "    filename = \"Data_\" + str(product) + \".csv\"\n",
    "    data = pd.read_csv(filename, index_col = 0)\n",
    "    print('We have {} reviews for the product {}'.format(data.shape[0], product))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72de86-4277-4400-85e8-dad65852ac92",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Fluctuating quality and/or Fraudulent reviews Detection</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99689442-bc62-40f3-bbc6-dabfcea084b5",
   "metadata": {},
   "source": [
    "We want to know what we're buying. The quality of a product should not rise or drop rapidly with\n",
    "changes in manufacturing or storage practices, or sellers. This is especially relevant on Amazon, where third parties are able to jump in to legitimate product pages, sometimes selling their fake versions of a product. The shoe company, Nike, for example, chose to completely cease sales on Amazon in 2019 due to unauthorized 3rd party sales and counterfeit products. \n",
    "\n",
    "We also want to be able to trust the reviews we read. Fraudulent reviews can occur, either to increase sales with five-star reviews, or to decrease sales of competitors with one-star reviews. \n",
    "\n",
    "Both fluctuating quality and fraudulent reviews would be reflected in the typical star-ratings over time. Decreasing quality would increase the rate of 1-star reviews. Fraudulent reviews would likely cause irregular spikes in the numbers of either positive or negative reviews. Many news sources claim that fraudulent, paid reviews are extremely common on Amazon, though I did not personally check whether there is strong evidence towards this claim. \n",
    "\n",
    "Let's define our null hypothesis as the hypothesis that a product has a consistent satisfaction rate. The percentage of negative ratings, let's say 1-, 2-, and 3-stars, should stay a constant fraction of the number of reviews, over time, though allowing for random fluctuations. We can detect statistically significant fluctuations using a chi-squared test, and compare the p-value with a statistical significance threshold to decide whether to reject the null hypothesis. Rejecting the null hypothesis would mean accepting the alternative hypothesis, that the percentage of apparently unhappy customers is changing statistically significantly over time. This can occur, for example, due to fluctuating quality or fraudulent reviews. \n",
    "\n",
    "In theory, the p-value should allow us to sometimes reject the null hypothesis, thereby labelling some products as having volatile ratings. This may not always be a valuable distinction, as other time-dependent factors like advertising might cause a spike in positive or negative ratings. As another product, products with fewer reviews will also tend to have higher p-values, because it is harder to reject the null hypothesis with fewer data points. \n",
    "\n",
    "In practice, then, we can only use the results of the chi-squared test if we've tested it on a large number of products, especially from the same category, and find that the results are sensible. This is not possible for me because my scraper was blocked by bot detection after I collected data for only four products. I will do the chi-squared test anyways on my four products, but a strong interpretation of the results would require much more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b48cb0-f126-42a9-9cc0-13dd8e6df218",
   "metadata": {},
   "source": [
    "In the code block below, I do a chi-squared test on the 'observed' number of negative ratings (1, 2, and 3 stars) versus the 'expected' number, defined as the mean percentage of negative ratings, times the total number of ratings within a given time period. I use only the data from the year 2021, the only full year when all of the products had a high enough number of sales and ratings for a chi-squared test to be valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7dffa5d0-9c28-415c-b759-88973c32277e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PampersWipes  has a chi-squared p-value of 0.11\n",
      "Nike  has a chi-squared p-value of 0.0036\n",
      "TurmericSupplement  has a chi-squared p-value of 0.00096\n",
      "N95  has a chi-squared p-value of 2.4e-20\n"
     ]
    }
   ],
   "source": [
    "def convert_monthly_series_to_list(series): \n",
    "        lst = []\n",
    "        for month in range(1, 13): \n",
    "            if month not in series.index:\n",
    "                lst.append(0)\n",
    "            else:\n",
    "                lst.append(series.loc[month])\n",
    "        return lst\n",
    "    \n",
    "for product in [\"PampersWipes\", \"Nike\", \"TurmericSupplement\", \"N95\"]:\n",
    "    \n",
    "    # Load data\n",
    "    filename = \"Data_\" + str(product) + \".csv\"\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    # Specify year and star-reviews \n",
    "    years = 2021\n",
    "    star_ratings = [1,2,3] # All of these are bad ratings. Even with 3 star ratings, 1-3 account for at MOST 15% of all ratings in the products I'm looking at.\n",
    "\n",
    "    # Total number of reviews, per month \n",
    "    totalByMonth = data.groupby([\"Year\", \"Month\"]).size().loc[year] \n",
    "    \n",
    "    # Percent with specified star ratings \n",
    "    percent = data[(data[\"Year\"] == year) & (data[\"Rating\"].isin(star_ratings))].shape[0] / data[(data[\"Year\"] == year)].shape[0]\n",
    "\n",
    "    # Expected versus Observed Bad Ratings\n",
    "    expected_series = totalByMonth * percent\n",
    "    observed_series = data[data[\"Rating\"].isin(star_ratings)].groupby([\"Year\", \"Month\"]).size().loc[year]\n",
    "    expected, observed = convert_monthly_series_to_list(expected_series), convert_monthly_series_to_list(observed_series)\n",
    "    \n",
    "    # Divide up data in different ways: 12 data points (every month), 6 (every two months), 4 (every three months), 3 (every four months).\n",
    "    # These can give different results in p-values, so it's worth checking the pvalue for all of them, and reporting the result. \n",
    "    min_pvalue = 1.0\n",
    "    for k in range(1, 4 + 1):\n",
    "        observed_k = [sum(observed[j] for j in range(i, i + k)) for i in range(0, 12, k)]\n",
    "        expected_k = [sum(expected[j] for j in range(i, i + k)) for i in range(0, 12, k)]\n",
    "        if any(x < 5 for x in (observed_k + expected_k)):\n",
    "            continue\n",
    "        min_pvalue = min(min_pvalue, chisquare(observed_k, expected_k).pvalue)\n",
    "    \n",
    "    print(product, ' has a chi-squared p-value of {0:1.2}'.format(min_pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5517a-c264-41f0-a2c5-0bdd52b6a775",
   "metadata": {},
   "source": [
    "With any conventional statistical significance threshold, the Nike shoes, Tumeric Supplement, and N95 masks fail the null hypothesis. They have statistically significant volatility in their star-ratings, indicating the possibility of volatile quality and/or fraudulent reviews.\n",
    "\n",
    "As with all statistical significance tests, we cannot say that Pampers Wipes 'succeeded' the null hypothesis - only that it does not fail. \n",
    "\n",
    "That said, we can take the higher p-value of Pampers Wipes as a vote of confidence in reliable, steady customer opinion. The average customer rating of 4.65 is something we can trust, at least relative to the average customer ratings of the other products. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d155671-b8bb-4e81-94ac-3d0530619972",
   "metadata": {},
   "source": [
    "#### <a id=\"1\"></a>\n",
    "# <p style=\"background-color:#8DB600;font-family:newtimeroman;color:#FFF9ED;font-size:100%;text-align:center;border-radius:10px 10px;\">Automatic Reporting of Product Pros and Cons</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c0d30-1c89-4d72-9afa-5049d479ff94",
   "metadata": {},
   "source": [
    "Amazon reviews can be highly informative, giving specific information on what each customer liked or disliked about the product. However, based on my own experience buying items on Amazon, I personally believe there are a few weaknesses to Amazon reviews:\n",
    "* It takes **a lot of time** to read enough reviews to get a balanced perspective on customer opinion. \n",
    "* **Information is sparse.** Many sentences are fluff, spent describing the product as amazing or horrible without making concrete statements about the products' features. These sentiment-focused sentences are not useful, because they do not give more information that the star-ratings provide. \n",
    "* The provided **key words** tend to be **positive or neutral**. This is true, at least, for the products we have data for, which are well-rated 4-5 star products. This makes it much harder to get a sense of the complaints that unhappy customers have with the product. \n",
    "\n",
    "In this section, I extract **positive and negative keywords** from customer reviews. I define positive (negative) keywords based on these four criteria: (1) occur much more often in positive (negative) reviews than in negative (positive) reviews, (2) occur at some minimum frequency in reviews, and (3) are not in a list of standard English stopwords, and (4) are not in a handmade list of sentimental, low-content words like 'good' or 'bad'.\n",
    "\n",
    "I will also print **brief snippets of reviews** that contain the keywords found. This is useful because the keywords are often, but not always, informative on their own. I believe the resulting collection of review snippets is both informative and concise, but this is up to personal opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71711814-1748-40df-8978-44b1868d283a",
   "metadata": {},
   "source": [
    "The code blocks below\n",
    "* define functions to extract positive and negative keywords\n",
    "* define functions to format printing output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "098772ae-cd75-4e18-9606-c7fe8cef07f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load data for any given product. \n",
    "def load_data(product: str):\n",
    "    filename = \"Data_\" + product + \".csv\"\n",
    "    return pd.read_csv(filename, index_col = 0)\n",
    "\n",
    "\n",
    "# Review stopwords: words that indicate quality, but do not provide concrete information about the product\n",
    "review_stopwords = ['good', 'great', 'excellent', 'fantastic', 'well', 'better', 'best', 'perfect', # positive adjectives\n",
    "                    'bad', 'terrible', 'horrible', 'worse', 'worst', # negative adjectives\n",
    "                    'love', 'luv', 'like', # positive verbs\n",
    "                    'hate', 'dislike', # negative verbs\n",
    "                    'dont', # common misspellings of stop words\n",
    "                    'really', 'seems', # other\n",
    "                   ]\n",
    "\n",
    "# Get key bad words and key good words\n",
    "def get_key_words(data, ratio_threshold = 3.0, min_frequency = 0.002, limit = 5):\n",
    "    # Join all bad vs good reviews, in a single string \n",
    "    bad_reviews = ' '.join(list(data[(data.Rating == 1) | (data.Rating == 2)].ReviewText.dropna())).lower()\n",
    "    good_reviews = ' '.join(list(data[data.Rating == 5].ReviewText.dropna())).lower()\n",
    "    \n",
    "    # Get rid of punctuation\n",
    "    punctuations = ['.', '!', '?', ';', ',', '(', ')', '/']\n",
    "    for char in punctuations:\n",
    "        bad_reviews = bad_reviews.replace(char, ' ')\n",
    "        good_reviews = good_reviews.replace(char, ' ')\n",
    "        \n",
    "    # Lemmatize ==> get good or bad words (not unique) and all words together (unique)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    all_bad = [lemmatizer.lemmatize(word) for word in bad_reviews.split()]\n",
    "    all_good = [lemmatizer.lemmatize(word) for word in good_reviews.split()]\n",
    "    words = set(all_bad + all_good)\n",
    "    \n",
    "    # Fill out dictionaries:\n",
    "    # frequency_bad_to_good: ratio of frequencies at which word appears, in bad reviews versus good reviews\n",
    "    # tf_bad (tf_good): term frequency of word in bad (good) reviews\n",
    "    frequency_bad_to_good, tf_bad, tf_good = {}, {}, {}\n",
    "    total_bad, total_good = len(all_bad), len(all_good)\n",
    "    for word in words:\n",
    "        tf_bad[word] = all_bad.count(word) / total_bad\n",
    "        tf_good[word] = all_good.count(word) / total_good\n",
    "        frequency_bad_to_good[word] = tf_bad[word] / tf_good[word] if tf_good[word] else np.inf\n",
    "\n",
    "    # Get key bad words, key good words\n",
    "    key_bad_words = [word for word in words\\\n",
    "         if (frequency_bad_to_good[word] > ratio_frequency_threshold) \\\n",
    "         & (tf_bad[word] > min_frequency) \\\n",
    "         & (word not in stopwords_lst + review_stopwords)]\n",
    "    key_good_words = [word for word in words\\\n",
    "         if (frequency_bad_to_good[word] < 1 / ratio_frequency_threshold) \\\n",
    "         & (tf_good[word] > min_frequency) \\\n",
    "         & (word not in stopwords_lst + review_stopwords)]\n",
    "    \n",
    "    # Keep only limit-# of key words, for each group \n",
    "    # Keep those with highest term frequency\n",
    "    key_bad_words = sorted(key_bad_words, key = lambda word: tf_bad[word], reverse = True)[:limit]\n",
    "    key_good_words = sorted(key_good_words, key = lambda word: tf_good[word], reverse = True)[:limit]\n",
    "    \n",
    "    return key_good_words, key_bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "757b3bd7-a94e-4a03-b251-b006cf0acba0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print colors (for formatting)\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "# Product names (For formatting)\n",
    "product_names = {'TurmericSupplement': \"Nature's Nutrition Turmeric Suppplements\",\n",
    "                 'N95': 'Fangtian N95 Masks',\n",
    "                 'PampersWipes' : 'Pampers Baby Wipes',\n",
    "                 'Nike': \"Nike Men's Sneakers\"}\n",
    "\n",
    "\n",
    "# Print key words\n",
    "def print_key_words(product: str, key_good_words: list, key_bad_words: list):\n",
    "    print(color.BOLD + product_names[product] + color.END + '\\n')\n",
    "\n",
    "    print(color.BOLD + color.GREEN + 'Key Words from Happy Customers:' + color.END)\n",
    "    print(color.BOLD + color.GREEN + ',  '.join(key_good_words) + color.END + '\\n')\n",
    "\n",
    "    print(color.BOLD + color.RED + 'Key Words from Unhappy Customers: ' + color.END)\n",
    "    print(color.BOLD + color.RED + ',  '.join(key_bad_words) + color.END + '\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "# Print review snippets\n",
    "def print_review_snippets(data, product, key_good_words, key_bad_words):\n",
    "    print(color.BOLD + product_names[product] + color.END + '\\n')\n",
    "    # Good and Bad reviews\n",
    "    good = ' '.join(list(data[data.Rating == 5].ReviewText.dropna()))\n",
    "    bad = ' '.join(list(data[data.Rating.isin([1,2])].ReviewText.dropna()))\n",
    "\n",
    "    for ctr in range(2):\n",
    "        # Define variables if GOOD (ctr = 0) or BAD (ctr = 1)\n",
    "        if ctr == 0:\n",
    "            reviews = good\n",
    "            key_words = key_good_words\n",
    "            mood_color = color.GREEN\n",
    "            print(color.BOLD + 'Snippets of Reviews from HAPPY Customers' + color.END)\n",
    "        elif ctr == 1:\n",
    "            reviews = bad\n",
    "            key_words = key_bad_words\n",
    "            mood_color = color.RED\n",
    "            print(color.BOLD + 'Snippets of Reviews from UNHAPPY Customers' + color.END)\n",
    "\n",
    "        # Get all sentences from reviews\n",
    "        sentences = [x.split('!') for x in reviews.split('.')]\n",
    "        sentences = [item for sublist in sentences for item in sublist] \n",
    "\n",
    "        for word in key_words:\n",
    "            # Get sentences that contain the key word\n",
    "            highlighted_sentences = [sentence for sentence in sentences if word in sentence.split(' ')]\n",
    "\n",
    "            # Print which key word you're looking at\n",
    "            print('\\n' + color.BOLD + mood_color + word.capitalize() + color.END + '\\n')\n",
    "\n",
    "            # Format sentences and print\n",
    "            for sentence in highlighted_sentences[:3]:\n",
    "                sentence_pieces = sentence.split(word)\n",
    "                formatted_sentence = ''\n",
    "                for piece in sentence_pieces[:-1]:\n",
    "                    formatted_sentence += piece\n",
    "                    formatted_sentence += color.BOLD + mood_color + word + color.END\n",
    "                formatted_sentence += sentence_pieces[-1]\n",
    "                formatted_sentence = formatted_sentence.strip().strip(')').strip() + '.'\n",
    "                print(formatted_sentence)\n",
    "\n",
    "        print('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527623f-2263-494f-aabb-a0e687ab32b3",
   "metadata": {},
   "source": [
    "See below for the positive keywords and negative keywords for each product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "f336b7ff-91ae-45e8-b652-12129557ae5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPampers Baby Wipes\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mKey Words from Happy Customers:\u001b[0m\n",
      "\u001b[1m\u001b[92msoft,  price,  work,  always,  gift\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mKey Words from Unhappy Customers: \u001b[0m\n",
      "\u001b[1m\u001b[91mrash,  dry,  bottom,  know,  old\u001b[0m\n",
      "\n",
      "\u001b[1mNature's Nutrition Turmeric Suppplements\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mKey Words from Happy Customers:\u001b[0m\n",
      "\u001b[1m\u001b[92mpain,  help,  joint,  inflammation,  arthritis\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mKey Words from Unhappy Customers: \u001b[0m\n",
      "\u001b[1m\u001b[91mbottle,  smell,  taste,  label,  per\u001b[0m\n",
      "\n",
      "\u001b[1mNike Men's Sneakers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mKey Words from Happy Customers:\u001b[0m\n",
      "\u001b[1m\u001b[92mfit,  comfortable,  price,  husband,  support\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mKey Words from Unhappy Customers: \u001b[0m\n",
      "\u001b[1m\u001b[91mmonth,  squeak,  toe,  week,  sole\u001b[0m\n",
      "\n",
      "\u001b[1mFangtian N95 Masks\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mKey Words from Happy Customers:\u001b[0m\n",
      "\u001b[1m\u001b[92mcomfortable,  n95,  feel,  seal,  glass\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mKey Words from Unhappy Customers: \u001b[0m\n",
      "\u001b[1m\u001b[91msmall,  bought,  uncomfortable,  size,  smell\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products = ['PampersWipes', 'TurmericSupplement', 'Nike', 'N95']\n",
    "for product in products:\n",
    "    data = load_data(product)\n",
    "    key_good_words, key_bad_words = get_key_words(data)\n",
    "    print_key_words(product, key_good_words, key_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51ca6c-c71e-41da-90cc-4959f02c58c7",
   "metadata": {},
   "source": [
    "Some comments on the keywords above:\n",
    "* Some key words are informative only when we account for the context - whether the key word came from positive or negative reviews. For example, the keyword 'price' under Pampers Baby Wipes is immediately informative because it comes from happy customers; people believe the price is good. The keyword 'month' under Nike Men's Sneakers comes from unhappy customers, so we know that something goes wrong over the course of a month-long timescale. \n",
    "* A couple key words, especially 'know' (Pampers Baby Wipes) and 'per' (Turmeric Supplements) and 'bought' (N95 Masks), don't tell us anything on their own. Fortunately these are uncommon. \n",
    "* The N95 mask keyword 'glass' should actually be 'glasses'. The keyword became 'glass' because of the lemmatizer I used. I don't know how I would avoid this problem, except manually or with a lemmatizer that can take context into account. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4549208-0626-43e0-a304-731f27abb527",
   "metadata": {},
   "source": [
    "Next, I print review snippets for each product. I believe these overviews are concise and possibly even more useful than raw Amazon reviews, because they remove distracting and time-consuming-to-read text and group together reviews by topic. However, this is up to personal opinion.\n",
    "\n",
    "One flaw is that each snippet is only a single sentence containing the key word, and so some sentences are not informative because they are taken out of the context of their review. The context could be improved with more sentences in each snippet, but this would come at the cost of conciseness.\n",
    "\n",
    "Scroll down to see the review snippets. Note that this is otherwise the end of our Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "7eefe7d8-4645-4417-8f80-1ef8383abf8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPampers Baby Wipes\u001b[0m\n",
      "\n",
      "\u001b[1mSnippets of Reviews from HAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mSoft\u001b[0m\n",
      "\n",
      "I would highly recommend if you’re baby had a sensitive bottom, I love how \u001b[1m\u001b[92msoft\u001b[0m they are too.\n",
      ":) Absolutely the best for babies and young kids, \u001b[1m\u001b[92msoft\u001b[0m for tender skin including their face.\n",
      "Very \u001b[1m\u001b[92msoft\u001b[0m and much larger then all the other brands I've tried.\n",
      "\n",
      "\u001b[1m\u001b[92mPrice\u001b[0m\n",
      "\n",
      "These are definitely my favorite wipes for the \u001b[1m\u001b[92mprice\u001b[0m.\n",
      "and u get only one pack for the same \u001b[1m\u001b[92mprice\u001b[0m.\n",
      "You get more for \u001b[1m\u001b[92mprice\u001b[0m of 2 wipes.\n",
      "\n",
      "\u001b[1m\u001b[92mWork\u001b[0m\n",
      "\n",
      "After food shopping and touching the wagons , after lunch especially if you have pizza or finger foods , at the laundromat if your detergent spills on your hands , and on a hot day coming home from \u001b[1m\u001b[92mwork\u001b[0m it’s a great way to start makeup removal , at the gym to freshen up as well.\n",
      "We need to buy laptop for \u001b[1m\u001b[92mwork\u001b[0m so I can make more money.\n",
      "I use these at \u001b[1m\u001b[92mwork\u001b[0m and at home for lots of cleanup needs.\n",
      "\n",
      "\u001b[1m\u001b[92mAlways\u001b[0m\n",
      "\n",
      "Free of alcohol, perfume, parabens, phenoxyethanol, and dyes \u001b[1m\u001b[92malways\u001b[0m good for little ones I couldn’t Take a picture.\n",
      "I \u001b[1m\u001b[92malways\u001b[0m buy these wipes.\n",
      "I'm \u001b[1m\u001b[92malways\u001b[0m pull 3-3 at a times.\n",
      "\n",
      "\u001b[1m\u001b[92mGift\u001b[0m\n",
      "\n",
      "These wipes are great for sensitive skin and they are thick and soft I bought these for a friend to give as a \u001b[1m\u001b[92mgift\u001b[0m at her baby shower… Apparently I was not the only one to see this amazing products because just about everybody bought these for her.\n",
      "This is a great product to \u001b[1m\u001b[92mgift\u001b[0m at a baby shower.\n",
      "Thank you INFINITY Ought these as part of baby shower \u001b[1m\u001b[92mgift\u001b[0m.\n",
      "\n",
      "\n",
      "\u001b[1mSnippets of Reviews from UNHAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mRash\u001b[0m\n",
      "\n",
      "The up and up ones are much softer and way less expensive but very similar Made my daughter break out in a horrible \u001b[1m\u001b[91mrash\u001b[0m that her pediatrician had to give her medicine for and she is still trying to heal I thought finding these wipes 6pk for 10$ was a deal so I jumped on it.\n",
      "For some reason my newborn nephew caught really bad \u001b[1m\u001b[91mrash\u001b[0m to this one I ordered compared to the same thing I buy from the store.\n",
      "My poor boy got the worst \u001b[1m\u001b[91mrash\u001b[0m he has ever had with these wipes, so badly he began bleeding.\n",
      "\n",
      "\u001b[1m\u001b[91mDry\u001b[0m\n",
      "\n",
      "The wipes at the top are \u001b[1m\u001b[91mdry\u001b[0m and the last few are very wet.\n",
      "They were \u001b[1m\u001b[91mdry\u001b[0m and not soft at all - like they had been left open.\n",
      "They aren’t the best they are \u001b[1m\u001b[91mdry\u001b[0m not really a wipe more like toilet paper they are thick I will give them that Came very \u001b[1m\u001b[91mdry\u001b[0m.\n",
      "\n",
      "\u001b[1m\u001b[91mBottom\u001b[0m\n",
      "\n",
      "After using these wipes my baby had red marks on his \u001b[1m\u001b[91mbottom\u001b[0m.\n",
      "My baby quickly developed a diaper rash using these wipes and screamed in pain when I would wipe his \u001b[1m\u001b[91mbottom\u001b[0m.\n",
      "The once on the top are dry and the once on the \u001b[1m\u001b[91mbottom\u001b[0m are soaking wet The only advantage: it’s not easy to dry out because they put too much liquid in the packs.\n",
      "\n",
      "\u001b[1m\u001b[91mKnow\u001b[0m\n",
      "\n",
      "I don't \u001b[1m\u001b[91mknow\u001b[0m of if its because they went bad for some reason maybe I got unlucky.\n",
      "I don't \u001b[1m\u001b[91mknow\u001b[0m if they did this purposely to get you to use more than you need or it's just a bad design but there is absolutely no way to pull just one out, especially one handed.\n",
      "I dont \u001b[1m\u001b[91mknow\u001b[0m if it is mold or what but it smells very very awful like I dont want this on any human let alone a baby.\n",
      "\n",
      "\u001b[1m\u001b[91mOld\u001b[0m\n",
      "\n",
      "Individual travel size packages Really bothered my 8mo \u001b[1m\u001b[91mold\u001b[0m daughters skin.\n",
      "Only ordered 1 bx Not a product for sensitive skin, I bought this for my 14 months \u001b[1m\u001b[91mold\u001b[0m and after two uses, he had the worst rash ever.\n",
      "Gave my 8 week \u001b[1m\u001b[91mold\u001b[0m daughter a bad rash within a day of using them Product arrived damaged Horrible horrible.\n",
      "\n",
      "\n",
      "\u001b[1mNature's Nutrition Turmeric Suppplements\u001b[0m\n",
      "\n",
      "\u001b[1mSnippets of Reviews from HAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mPain\u001b[0m\n",
      "\n",
      "I haven't finished the bottle yet, but I am feeling less inflammation and \u001b[1m\u001b[92mpain\u001b[0m.\n",
      "I have degenerated disc in my back which are causing nerve \u001b[1m\u001b[92mpain\u001b[0m.\n",
      "A couple years ago, I couldn’t sleep from my \u001b[1m\u001b[92mpain\u001b[0m.\n",
      "\n",
      "\u001b[1m\u001b[92mHelp\u001b[0m\n",
      "\n",
      "We went over a few studies which showed that it is a natural fat blocker which can \u001b[1m\u001b[92mhelp\u001b[0m with weight loss by decreasing inflammation in the body.\n",
      "I was taking straight Turmeric to \u001b[1m\u001b[92mhelp\u001b[0m with my joints and a holistic practitioner/friend encouraged me to try Turmeric with pepper because of the better absorption.\n",
      "When I say, \"I tried everything to \u001b[1m\u001b[92mhelp\u001b[0m with the pain\",.\n",
      "\n",
      "\u001b[1m\u001b[92mJoint\u001b[0m\n",
      "\n",
      "So I read that turmeric with bioprene works well for inflammation and \u001b[1m\u001b[92mjoint\u001b[0m pain.\n",
      "UPDATE:  Still using this brand and getting the same outstanding relief from \u001b[1m\u001b[92mjoint\u001b[0m pain.\n",
      "My \u001b[1m\u001b[92mjoint\u001b[0m pain has taken more time to lessen and headaches have even eased and I have been on topomax for migraines for some time but still always had to take headache powders at least four days a week bc of sinus headaches.\n",
      "\n",
      "\u001b[1m\u001b[92mInflammation\u001b[0m\n",
      "\n",
      "We went over a few studies which showed that it is a natural fat blocker which can help with weight loss by decreasing \u001b[1m\u001b[92minflammation\u001b[0m in the body.\n",
      "I haven't finished the bottle yet, but I am feeling less \u001b[1m\u001b[92minflammation\u001b[0m and pain.\n",
      "This helps eliminate \u001b[1m\u001b[92minflammation\u001b[0m & helps with the pain.\n",
      "\n",
      "\u001b[1m\u001b[92mArthritis\u001b[0m\n",
      "\n",
      "I never expected this to work, but 2 weeks into taking it and I just realized that my \u001b[1m\u001b[92marthritis\u001b[0m pain is GONE.\n",
      "for her \u001b[1m\u001b[92marthritis\u001b[0m.\n",
      "Hahaha I am 66 and I have \u001b[1m\u001b[92marthritis\u001b[0m and crones.\n",
      "\n",
      "\n",
      "\u001b[1mSnippets of Reviews from UNHAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mBottle\u001b[0m\n",
      "\n",
      "This is the 2nd time I order from this company and look at the difference on the pill the orange one it’s first \u001b[1m\u001b[91mbottle\u001b[0m and the brown one it’s the 2 \u001b[1m\u001b[91mbottle\u001b[0m.\n",
      "With the first \u001b[1m\u001b[91mbottle\u001b[0m I could feel a difference but with the second one, I’m still in pain.\n",
      "This was a re order and the \u001b[1m\u001b[91mbottle\u001b[0m and ingredients are exact but the pill is a different size and color.\n",
      "\n",
      "\u001b[1m\u001b[91mSmell\u001b[0m\n",
      "\n",
      "You can \u001b[1m\u001b[91msmell\u001b[0m the turmeric and the color is orange.\n",
      "I just discovered the other night that my recent purchase looks nothing like turmeric and has no \u001b[1m\u001b[91msmell\u001b[0m.\n",
      "I opened a capsule and there is still no \u001b[1m\u001b[91msmell\u001b[0m.\n",
      "\n",
      "\u001b[1m\u001b[91mTaste\u001b[0m\n",
      "\n",
      "I bought these capsules as I thought they would be easy to swallow and would have no \u001b[1m\u001b[91mtaste\u001b[0m-- but instead they reek like no other pills I have smelled before, and they \u001b[1m\u001b[91mtaste\u001b[0m even worse.\n",
      "Luckily I found some other Turmeric caplets at home and found that they don't smell nor \u001b[1m\u001b[91mtaste\u001b[0m badly.\n",
      "No smell, no \u001b[1m\u001b[91mtaste\u001b[0m apparently.\n",
      "\n",
      "\u001b[1m\u001b[91mLabel\u001b[0m\n",
      "\n",
      "This is the part of the \u001b[1m\u001b[91mlabel\u001b[0m not shown in the product information provided.\n",
      "Shame on Amazon for not displaying this part of the \u001b[1m\u001b[91mlabel\u001b[0m.\n",
      "2) Nature's Nutrition is not a \"real\" supplement company - it's a \u001b[1m\u001b[91mlabel\u001b[0m that SilverOnyx slaps on its products.\n",
      "\n",
      "\u001b[1m\u001b[91mPer\u001b[0m\n",
      "\n",
      "The instructions on the bottle say to take one capsule three times \u001b[1m\u001b[91mper\u001b[0m day.\n",
      "So I took a couple days off to recover and then started taking just one capsule \u001b[1m\u001b[91mper\u001b[0m day in the morning.\n",
      "The label states 1950mg but fine print is only 150mg \u001b[1m\u001b[91mper\u001b[0m 3 capsules.\n",
      "\n",
      "\n",
      "\u001b[1mNike Men's Sneakers\u001b[0m\n",
      "\n",
      "\u001b[1mSnippets of Reviews from HAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mFit\u001b[0m\n",
      "\n",
      "I own 3 pairs of these shoes in various colors, and they all \u001b[1m\u001b[92mfit\u001b[0m well.\n",
      "They still \u001b[1m\u001b[92mfit\u001b[0m my foot very well.\n",
      "These actually \u001b[1m\u001b[92mfit\u001b[0m without stretching out for a month first.\n",
      "\n",
      "\u001b[1m\u001b[92mComfortable\u001b[0m\n",
      "\n",
      "As for the comfort well these have always been some of the most \u001b[1m\u001b[92mcomfortable\u001b[0m sneakers I've ever owned.\n",
      "They are also very \u001b[1m\u001b[92mcomfortable\u001b[0m.\n",
      "these are well made, long-lasting, \u001b[1m\u001b[92mcomfortable\u001b[0m shoes and they're priced right.\n",
      "\n",
      "\u001b[1m\u001b[92mPrice\u001b[0m\n",
      "\n",
      "Highly recommended especially for the \u001b[1m\u001b[92mprice\u001b[0m My husband is a home inspector.\n",
      "This is the second pair of these shoes I have purchased at a far lower \u001b[1m\u001b[92mprice\u001b[0m then currently \u001b[1m\u001b[92mprice\u001b[0md today.\n",
      "Both of my white shoes were purchased from Amazon for they had the best \u001b[1m\u001b[92mprice\u001b[0m at that time.\n",
      "\n",
      "\u001b[1m\u001b[92mHusband\u001b[0m\n",
      "\n",
      "Highly recommended especially for the price My \u001b[1m\u001b[92mhusband\u001b[0m is a home inspector.\n",
      "This is the third pair of shoes my \u001b[1m\u001b[92mhusband\u001b[0m has worn for years.\n",
      "My \u001b[1m\u001b[92mhusband\u001b[0m bought a pair of these sometime ago.\n",
      "\n",
      "\u001b[1m\u001b[92mSupport\u001b[0m\n",
      "\n",
      "While these shoes do have \"decent\" arch \u001b[1m\u001b[92msupport\u001b[0m, it is just not enough \u001b[1m\u001b[92msupport\u001b[0m for my feet.\n",
      "These above shoes have great \u001b[1m\u001b[92msupport\u001b[0m with 6 eyelets and firm outer leather construction to allow one good mobility to function.\n",
      "Not necessarily made for running,  perhaps in the Gym it may give enough \u001b[1m\u001b[92msupport\u001b[0m.\n",
      "\n",
      "\n",
      "\u001b[1mSnippets of Reviews from UNHAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mMonth\u001b[0m\n",
      "\n",
      "I have worn them for a \u001b[1m\u001b[91mmonth\u001b[0m and a half.\n",
      "Within 1 week the air cushion on the right started to squeak, and 1 \u001b[1m\u001b[91mmonth\u001b[0m later, both shoes squeak.\n",
      "August 24, 2021:  After a \u001b[1m\u001b[91mmonth\u001b[0m they started squeaking too.\n",
      "\n",
      "\u001b[1m\u001b[91mSqueak\u001b[0m\n",
      "\n",
      "When on  my last year's pair one shoe began to \u001b[1m\u001b[91msqueak\u001b[0m after a few months  I figured it was just worn out from walking 4 miles a day.\n",
      "This year I ordered another pair and right out of the box one shoe had a terrible \u001b[1m\u001b[91msqueak\u001b[0m.\n",
      "The 2nd pair had only a slight \u001b[1m\u001b[91msqueak\u001b[0m out of the box but now just  after the return policy deadline ended the \u001b[1m\u001b[91msqueak\u001b[0m is  progressively getting so loud I  am embarrassed to wear them in public.\n",
      "\n",
      "\u001b[1m\u001b[91mToe\u001b[0m\n",
      "\n",
      "While the uppers and soles are within a few months of new, the center part of the \u001b[1m\u001b[91mtoe\u001b[0m starts to separate and quickly fails.\n",
      "These are probably the worse shoes I have ever worn in my life and I use to wear big ass steel \u001b[1m\u001b[91mtoe\u001b[0m boots.\n",
      "After a few months of everyday wear (walking/standing) the sole started coming away form the upper at the \u001b[1m\u001b[91mtoe\u001b[0m.\n",
      "\n",
      "\u001b[1m\u001b[91mWeek\u001b[0m\n",
      "\n",
      "Wore them one \u001b[1m\u001b[91mweek\u001b[0m and the rubber sole came off and the company wanted a 50% restocking fee and I had to pay for shipping.\n",
      "the first pair began to squeak very loudly after about a \u001b[1m\u001b[91mweek\u001b[0m.\n",
      "Within 1 \u001b[1m\u001b[91mweek\u001b[0m the air cushion on the right started to squeak, and 1 month later, both shoes squeak.\n",
      "\n",
      "\u001b[1m\u001b[91mSole\u001b[0m\n",
      "\n",
      "On my last four pair, the left shoe (first, then right) has had the \u001b[1m\u001b[91msole\u001b[0m become unglued from the shoe.\n",
      "Wore them one week and the rubber \u001b[1m\u001b[91msole\u001b[0m came off and the company wanted a 50% restocking fee and I had to pay for shipping.\n",
      "They only lasted about 5 months when the \u001b[1m\u001b[91msole\u001b[0m came off the back of the right shoe.\n",
      "\n",
      "\n",
      "\u001b[1mFangtian N95 Masks\u001b[0m\n",
      "\n",
      "\u001b[1mSnippets of Reviews from HAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mComfortable\u001b[0m\n",
      "\n",
      "The mask ended up being a very well made and \u001b[1m\u001b[92mcomfortable\u001b[0m one for most of our team members.\n",
      "They were similar to the BYD foldable masks that Governor Newsom donated to us a few months ago, but far more \u001b[1m\u001b[92mcomfortable\u001b[0m.\n",
      "As a physician I have used many different types of N-95s , these are very \u001b[1m\u001b[92mcomfortable\u001b[0m and achieved an appropriate fit with a proper seal.\n",
      "\n",
      "\u001b[1m\u001b[92mN95\u001b[0m\n",
      "\n",
      "A few months ago, I came across this seller on Amazon business and decided to try out their cone shaped \u001b[1m\u001b[92mn95\u001b[0m mask.\n",
      "Just as we were about to place our order for more, we noticed this new foldable \u001b[1m\u001b[92mn95\u001b[0m and decided to give it a try.\n",
      "Overall, we are very satisfied with this manufacturer's two \u001b[1m\u001b[92mn95\u001b[0m models and can finally stop worrying about having enough masks for our team.\n",
      "\n",
      "\u001b[1m\u001b[92mFeel\u001b[0m\n",
      "\n",
      "These fit secure and \u001b[1m\u001b[92mfeel\u001b[0m safe.\n",
      "I would definitely \u001b[1m\u001b[92mfeel\u001b[0m safe it I wore this mask in a crowded place where I was unable to socially distance or if I need to be on a plane and want extra comfort.\n",
      "Would not \u001b[1m\u001b[92mfeel\u001b[0m comfortable wearing it during cardio.\n",
      "\n",
      "\u001b[1m\u001b[92mSeal\u001b[0m\n",
      "\n",
      "The flexibility of the fabric allows for a nice tight \u001b[1m\u001b[92mseal\u001b[0m to all of our team members faces, no matter the face size.\n",
      "As a physician I have used many different types of N-95s , these are very comfortable and achieved an appropriate fit with a proper \u001b[1m\u001b[92mseal\u001b[0m.\n",
      "The padding around the nose is great; the \u001b[1m\u001b[92mseal\u001b[0m is perfect, and I most definitely recommend this purchase.\n",
      "\n",
      "\u001b[1m\u001b[92mGlass\u001b[0m\n",
      "\n",
      "Since i have been wearing masks, fog on \u001b[1m\u001b[92mglass\u001b[0m is a real issue for me.\n",
      "\n",
      "\n",
      "\u001b[1mSnippets of Reviews from UNHAPPY Customers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91mSmall\u001b[0m\n",
      "\n",
      "They are soft, light weight and fit well if you have a \u001b[1m\u001b[91msmall\u001b[0m face.\n",
      "It would be excellent for a very \u001b[1m\u001b[91msmall\u001b[0m person.\n",
      "I have a \u001b[1m\u001b[91msmall\u001b[0m head.\n",
      "\n",
      "\u001b[1m\u001b[91mBought\u001b[0m\n",
      "\n",
      "I \u001b[1m\u001b[91mbought\u001b[0m these to wear on a flight and these do not seem appropriate for that purpose, I was looking for a better quality mask and these seem much less secure than KN95s I normally use which are a fraction of the cost.\n",
      "That said the box I \u001b[1m\u001b[91mbought\u001b[0m just about  every mask broke an elastic straps until about the 7th one.\n",
      "The masks smell from chemicals give me a headache Do not Buy I \u001b[1m\u001b[91mbought\u001b[0m this mask for added protection to wear on an airplane.\n",
      "\n",
      "\u001b[1m\u001b[91mUncomfortable\u001b[0m\n",
      "\n",
      "Definitely a waste This is a snug fitting mask that is not \u001b[1m\u001b[91muncomfortable\u001b[0m.\n",
      "It was \u001b[1m\u001b[91muncomfortable\u001b[0m & looked like a bird beak.\n",
      "I did not like the nose bridge foam and found it \u001b[1m\u001b[91muncomfortable\u001b[0m.\n",
      "\n",
      "\u001b[1m\u001b[91mSize\u001b[0m\n",
      "\n",
      "I got the larger \u001b[1m\u001b[91msize\u001b[0m because I planned to share with my husband.\n",
      "Useless as a  face mask for someone my shape and \u001b[1m\u001b[91msize\u001b[0m.\n",
      "My hat \u001b[1m\u001b[91msize\u001b[0m is 7.\n",
      "\n",
      "\u001b[1m\u001b[91mSmell\u001b[0m\n",
      "\n",
      "The masks \u001b[1m\u001b[91msmell\u001b[0m from chemicals give me a headache Do not Buy I bought this mask for added protection to wear on an airplane.\n",
      "I’ve washed my hands many times and they still \u001b[1m\u001b[91msmell\u001b[0m.\n",
      "I can't wear this with that \u001b[1m\u001b[91msmell\u001b[0m.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products = ['PampersWipes', 'TurmericSupplement', 'Nike', 'N95']\n",
    "for product in products:\n",
    "    data = load_data(product)\n",
    "    key_good_words, key_bad_words = get_key_words(data)\n",
    "    print_review_snippets(data, product, key_good_words, key_bad_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
